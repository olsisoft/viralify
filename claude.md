# Viralify - Claude Code Context

---

## R√®gles de travail Claude

### Processus obligatoire avant tout changement de code

1. **Comprendre** - Lire les fichiers concern√©s, ne jamais supposer
2. **Expliquer** - D√©crire le probl√®me tel que compris
3. **Proposer** - Pr√©senter 2-3 approches avec pros/cons
4. **Valider** - Attendre l'approbation explicite de l'utilisateur
5. **Impl√©menter** - √âcrire le code seulement apr√®s validation
6. **Montrer** - Afficher le diff avant de commit
7. **Confirmer** - Attendre l'approbation pour commit/push

### Ne jamais faire sans validation

- Changements architecturaux
- Ajout de d√©pendances
- Modification de fichiers de config (docker-compose, etc.)
- Suppression de code existant
- Refactoring non demand√©

### Session tracking

**Dernier commit:** `f140b1c` - feat: implement sync anchors as hard constraints in SSVS algorithm
**Date:** 2026-01-23
**Travail en cours:** SSVS complet avec anchors, embeddings configurables, calibration

---

## Project Overview

Viralify est une plateforme de cr√©ation de contenu viral pour les r√©seaux sociaux, avec un focus particulier sur la g√©n√©ration automatis√©e de cours vid√©o √©ducatifs.

### Niche Tech - Plateforme pour toute la Tech IT

Cette plateforme est con√ßue pour couvrir **l'ensemble de l'√©cosyst√®me IT**, incluant:
- **545+ m√©tiers** tech (Data Engineer, MLOps Engineer, Cloud Architect, etc.)
- **80+ domaines** (Data Engineering, DevOps, Cybersecurity, Quantum Computing, etc.)
- **120+ langages** de programmation (Python, Go, Rust, Solidity, Qiskit, etc.)

Les agents g√©n√®rent du contenu adapt√© √† chaque profil, niveau et domaine technique.

## Architecture

### Services principaux
- **frontend** (Next.js) - Port 3000
- **api-gateway** (Spring Boot) - Port 8080
- **course-generator** (FastAPI) - Port 8007
- **presentation-generator** (FastAPI) - Port 8006
- **media-generator** (FastAPI) - Port 8004
- **visual-generator** (FastAPI) - Port 8003 (microservice diagrammes)

### Infrastructure
- PostgreSQL, Redis, RabbitMQ, Elasticsearch
- **Kroki** - Self-hosted diagram rendering (Mermaid, PlantUML, D2, GraphViz)
- Docker Compose pour l'orchestration

---

## Course Generator - Roadmap

### Phase 1: √âl√©ments de le√ßon adaptatifs + Quiz (ACTUELLE)

#### Objectifs
1. **Option A** - Mapping des √©l√©ments par cat√©gorie de profil
2. **Option C** - Suggestion IA des √©l√©ments selon le sujet
3. **Quiz obligatoires** - Tous les cours incluent des √©valuations

#### √âl√©ments par cat√©gorie

| Cat√©gorie | √âl√©ments sp√©cifiques |
|-----------|---------------------|
| **Tech** | `code_demo`, `terminal_output`, `architecture_diagram`, `debug_tips` |
| **Business** | `case_study`, `framework_template`, `roi_metrics`, `action_checklist`, `market_analysis` |
| **Health** | `exercise_demo`, `safety_warning`, `body_diagram`, `progression_plan`, `rest_guidance` |
| **Creative** | `before_after`, `technique_demo`, `tool_tutorial`, `creative_exercise`, `critique_section` |
| **Education** | `memory_aid`, `practice_problem`, `multiple_explanations`, `summary_card` |
| **Lifestyle** | `daily_routine`, `reflection_exercise`, `goal_setting`, `habit_tracker`, `milestone` |

#### √âl√©ments communs (tous les cours)

| √âl√©ment | Description | Obligatoire |
|---------|-------------|-------------|
| `concept_intro` | Introduction du concept principal | Oui |
| `voiceover` | Narration explicative | Oui |
| `curriculum_slide` | Position dans le cours | Oui |
| `conclusion` | R√©capitulatif des points cl√©s | Oui |
| `quiz_evaluation` | Quiz interactif | **Oui** |

#### Configuration des Quiz

- **Format**: Style Udemy (QCM, Vrai/Faux, association, r√©ponses courtes)
- **Fr√©quence**: Configurable par l'utilisateur au frontend
  - Par lecture
  - Par section
  - √Ä la fin du cours uniquement
  - Personnalis√© (toutes les N lectures)
- **G√©n√©ration**: L'IA g√©n√®re les questions bas√©es sur le contenu de la le√ßon

#### Suggestion IA (Option C)

L'IA analyse le sujet, la description et le contexte pour:
1. D√©tecter automatiquement la cat√©gorie si non sp√©cifi√©e
2. Sugg√©rer les √©l√©ments les plus pertinents avec score de pertinence
3. Proposer des √©l√©ments additionnels bas√©s sur le sujet sp√©cifique

---

### Phase 2: RAG - Documentation Source (COMPL√âT√âE + INT√âGR√âE + 90% GARANTI)

#### Objectifs
L'utilisateur peut uploader des documents comme source de contenu pour la g√©n√©ration de cours.
Le syst√®me garantit que **90% minimum** du contenu g√©n√©r√© provient des documents source.

#### Formats support√©s
- PDF (via PyMuPDF)
- Word (DOCX, DOC)
- PowerPoint (PPTX, PPT)
- Texte (TXT, MD)
- Excel (XLSX, XLS, CSV)
- URLs/pages web
- Vid√©os YouTube (transcription via youtube-transcript-api)

#### S√©curit√© des documents (Impl√©ment√©e)
- **Validation du type MIME** avec python-magic
- **V√©rification extension vs contenu** r√©el
- **D√©tection de macros** (VBA dans Office)
- **D√©tection d'objets embarqu√©s** dangereux
- **Limite de taille** par type de fichier (50 MB max)
- **D√©tection de patterns malicieux** (injection, scripts)
- **Protection zip bomb** (ratio de compression)
- **Sanitization des noms de fichiers**

#### Architecture RAG (Impl√©ment√©e)
```
services/course-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ document_models.py     # Document, DocumentChunk, RAGQuery models
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ security_scanner.py    # Validation s√©curit√© compl√®te
    ‚îú‚îÄ‚îÄ document_parser.py     # Extraction multi-format
    ‚îú‚îÄ‚îÄ vector_store.py        # Embeddings OpenAI + ChromaDB/Memory
    ‚îî‚îÄ‚îÄ retrieval_service.py   # Orchestration RAG compl√®te
```

#### Endpoints API Documents
- `POST /api/v1/documents/upload` - Upload fichier
- `POST /api/v1/documents/upload-url` - Import URL/YouTube
- `GET /api/v1/documents` - Liste documents
- `GET /api/v1/documents/{id}` - D√©tails document
- `DELETE /api/v1/documents/{id}` - Supprimer
- `POST /api/v1/documents/query` - Recherche RAG
- `GET /api/v1/documents/context/{course_id}` - Contexte pour g√©n√©ration

#### Frontend Components
- `lib/document-types.ts` - Types TypeScript
- `components/DocumentUpload.tsx` - Upload drag & drop + URL

---

### Phase 3: √âdition Vid√©o Utilisateur (COMPL√âT√âE)

#### Objectifs
L'utilisateur peut modifier la vid√©o de cours g√©n√©r√©e et ajouter ses propres enregistrements.

#### Fonctionnalit√©s
- Visualisation de la timeline du cours
- Remplacement de segments vid√©o
- Ajout d'enregistrements personnels (webcam, screen recording)
- Ajustement de la synchronisation audio/vid√©o
- Insertion de slides personnalis√©es
- Trim/cut des sections
- Transitions entre segments
- Overlays texte et image
- Export vid√©o final

#### Architecture Backend (media-generator)
```
services/media-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ video_editor_models.py    # Mod√®les Pydantic (VideoProject, VideoSegment, etc.)
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ timeline_service.py       # Gestion timeline + ProjectRepository
    ‚îú‚îÄ‚îÄ segment_manager.py        # Upload et traitement des m√©dias
    ‚îî‚îÄ‚îÄ video_merge_service.py    # Rendu FFmpeg final
```

#### Endpoints API Video Editor
- `POST /api/v1/editor/projects` - Cr√©er un projet
- `GET /api/v1/editor/projects` - Lister les projets
- `GET /api/v1/editor/projects/{id}` - D√©tails projet
- `DELETE /api/v1/editor/projects/{id}` - Supprimer projet
- `PATCH /api/v1/editor/projects/{id}/settings` - Param√®tres projet
- `POST /api/v1/editor/projects/{id}/segments` - Ajouter segment
- `POST /api/v1/editor/projects/{id}/segments/upload` - Upload m√©dia
- `PATCH /api/v1/editor/projects/{id}/segments/{segId}` - Modifier segment
- `DELETE /api/v1/editor/projects/{id}/segments/{segId}` - Supprimer segment
- `POST /api/v1/editor/projects/{id}/segments/reorder` - R√©ordonner
- `POST /api/v1/editor/projects/{id}/segments/{segId}/split` - Diviser segment
- `POST /api/v1/editor/projects/{id}/overlays/text` - Overlay texte
- `POST /api/v1/editor/projects/{id}/overlays/image` - Overlay image
- `POST /api/v1/editor/projects/{id}/render` - Lancer le rendu
- `GET /api/v1/editor/render-jobs/{jobId}` - Statut rendu
- `POST /api/v1/editor/projects/{id}/preview` - Preview rapide
- `GET /api/v1/editor/supported-formats` - Formats support√©s

#### Frontend Components (editor)
```
frontend/src/app/dashboard/studio/editor/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ editor-types.ts           # Types TypeScript
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îî‚îÄ‚îÄ useVideoEditor.ts         # Hook React pour l'API
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ Timeline.tsx              # Timeline principale
‚îÇ   ‚îú‚îÄ‚îÄ SegmentItem.tsx           # Item de segment
‚îÇ   ‚îî‚îÄ‚îÄ SegmentProperties.tsx     # Panel propri√©t√©s
‚îî‚îÄ‚îÄ page.tsx                      # Page √©diteur
```

#### Formats support√©s
- **Vid√©o**: mp4, mov, avi, mkv, webm, m4v (max 500 MB)
- **Audio**: mp3, wav, aac, m4a, ogg (max 50 MB)
- **Image**: jpg, jpeg, png, gif, webp (max 10 MB)

---

### Phase 4: Voice Cloning (COMPL√âT√âE)

#### Objectifs
L'utilisateur peut cloner sa voix pour personnaliser la narration des cours.

#### Fonctionnalit√©s
- Upload d'√©chantillons vocaux (minimum 30 secondes)
- Analyse qualit√© audio (bruit, clart√©)
- Entra√Ænement du mod√®le via ElevenLabs API
- G√©n√©ration TTS avec la voix clon√©e
- Ajustement stabilit√©, similarit√©, style
- Preview avant g√©n√©ration compl√®te
- Consentement explicite obligatoire

#### Provider
- **ElevenLabs** - Instant Voice Cloning API
- Mod√®le: eleven_multilingual_v2
- Output: MP3 44.1kHz

#### Architecture Backend (media-generator)
```
services/media-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ voice_cloning_models.py     # VoiceProfile, VoiceSample, etc.
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ voice_sample_service.py     # Upload + validation audio
    ‚îú‚îÄ‚îÄ voice_cloning_service.py    # Int√©gration ElevenLabs
    ‚îî‚îÄ‚îÄ voice_profile_manager.py    # Orchestration workflow
```

#### Endpoints API Voice Cloning
- `POST /api/v1/voice/profiles` - Cr√©er profil vocal
- `GET /api/v1/voice/profiles` - Lister profils
- `GET /api/v1/voice/profiles/{id}` - D√©tails profil
- `DELETE /api/v1/voice/profiles/{id}` - Supprimer profil
- `PATCH /api/v1/voice/profiles/{id}` - Modifier profil
- `POST /api/v1/voice/profiles/{id}/samples` - Upload √©chantillon
- `DELETE /api/v1/voice/profiles/{id}/samples/{sampleId}` - Supprimer √©chantillon
- `POST /api/v1/voice/profiles/{id}/train` - D√©marrer entra√Ænement
- `GET /api/v1/voice/profiles/{id}/training-status` - Statut entra√Ænement
- `POST /api/v1/voice/profiles/{id}/generate` - G√©n√©rer audio
- `POST /api/v1/voice/profiles/{id}/preview` - Preview rapide
- `GET /api/v1/voice/requirements` - Requis pour √©chantillons
- `GET /api/v1/voice/usage` - Stats utilisation API

#### Frontend Components (voice-clone)
```
frontend/src/app/dashboard/studio/voice-clone/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ voice-types.ts              # Types TypeScript
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îî‚îÄ‚îÄ useVoiceClone.ts            # Hook React pour l'API
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ VoiceSampleUpload.tsx       # Upload avec drag & drop
‚îî‚îÄ‚îÄ page.tsx                        # Page gestion des voix
```

#### Requirements √©chantillons
- **Formats**: mp3, wav, m4a, ogg, webm, flac, aac
- **Dur√©e par sample**: 5-300 secondes
- **Dur√©e totale min**: 30 secondes
- **Dur√©e id√©ale**: 60 secondes
- **Taille max**: 50 MB par fichier

#### S√©curit√© & Consentement
- Consentement explicite obligatoire avant entra√Ænement
- Enregistrement IP et timestamp du consentement
- Profils suspendables en cas d'abus

---

## D√©cisions techniques

### Choisies
- [x] √âl√©ments adaptatifs par cat√©gorie (Option A)
- [x] Suggestion IA des √©l√©ments (Option C)
- [x] Quiz obligatoires format Udemy
- [x] Fr√©quence quiz configurable par utilisateur
- [x] Support multi-format documents (Phase 2)
- [x] Validation s√©curit√© documents obligatoire
- [x] Vector store: ChromaDB par d√©faut, InMemory pour dev, architecture extensible
- [x] Embeddings: OpenAI text-embedding-3-small
- [x] Code generation: GPT-4o avec TechPromptBuilder contextuel (Phase 6)
- [x] Diagrammes: Librairie Diagrams (Python) avec ic√¥nes AWS/Azure/GCP (Phase 6)
- [x] Couverture tech: 545+ m√©tiers, 80+ domaines, 120+ langages (Phase 6)

### En attente
- [x] Provider de voice cloning: ElevenLabs (Phase 4 compl√©t√©e)
- [x] √âditeur vid√©o: web-based (Phase 3 compl√©t√©e)
- [x] Migration vector store vers pgvector pour production (Phase 5)
- [x] Analytics & Metrics (Phase 5A)
- [x] Multi-langue 10 langues (Phase 5B)
- [x] Mon√©tisation Stripe + PayPal (Phase 5C)
- [x] Collaboration avec √©quipes (Phase 5D)
- [x] Enhanced code/diagram generation (Phase 6 compl√©t√©e)

---

## Phase 1 - Impl√©mentation (COMPL√âT√âE)

### Backend (course-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/lesson_elements.py` - Mod√®les pour √©l√©ments par cat√©gorie + quiz
- `services/element_suggester.py` - Service IA de suggestion d'√©l√©ments (Option C)
- `services/quiz_generator.py` - G√©n√©rateur de quiz style Udemy

**Fichiers modifi√©s:**
- `models/course_models.py` - Ajout QuizConfigRequest, AdaptiveElementsRequest
- `main.py` - Nouveaux endpoints API

**Nouveaux endpoints API:**
- `GET /api/v1/courses/config/categories` - Liste des cat√©gories
- `GET /api/v1/courses/config/elements/{category}` - √âl√©ments par cat√©gorie
- `POST /api/v1/courses/config/suggest-elements` - Suggestion IA
- `GET /api/v1/courses/config/detect-category` - D√©tection auto cat√©gorie
- `GET /api/v1/courses/config/quiz-options` - Options de quiz

### Frontend (courses)

**Nouveaux fichiers cr√©√©s:**
- `lib/lesson-elements.ts` - Types TypeScript pour √©l√©ments et quiz
- `components/AdaptiveLessonElements.tsx` - Composant √©l√©ments adaptatifs
- `components/QuizConfigPanel.tsx` - Configuration des quiz

**Fichiers modifi√©s:**
- `lib/course-types.ts` - Ajout QuizConfig, AdaptiveElementsConfig
- `page.tsx` - √âtat initial avec quiz et √©l√©ments adaptatifs

---

## Phase 2 - Impl√©mentation (COMPL√âT√âE)

### Backend (course-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/document_models.py` - Mod√®les Document, DocumentChunk, RAG
  - Document: m√©tadonn√©es fichier, statut, chunks
  - DocumentChunk: contenu + embedding pour RAG
  - SecurityScanResult: r√©sultats validation s√©curit√©
  - RAGQueryRequest/Response: requ√™tes de recherche
- `services/security_scanner.py` - Validation s√©curit√© compl√®te
  - Validation MIME type avec libmagic
  - D√©tection macros VBA
  - D√©tection objets embarqu√©s dangereux
  - Protection path traversal et zip bombs
  - Patterns malicieux (scripts, injection)
- `services/document_parser.py` - Extraction multi-format
  - PDF via PyMuPDF
  - DOCX/DOC via python-docx
  - PPTX/PPT via python-pptx
  - XLSX/XLS via openpyxl/xlrd
  - CSV, TXT, Markdown
  - URLs via httpx + BeautifulSoup
  - YouTube via youtube-transcript-api
- `services/vector_store.py` - Embeddings et stockage
  - EmbeddingService: OpenAI text-embedding-3-small
  - ChromaVectorStore: backend ChromaDB
  - InMemoryVectorStore: backend d√©veloppement
  - VectorStoreFactory: abstraction backends
- `services/retrieval_service.py` - Orchestration RAG
  - Upload et processing documents
  - Recherche s√©mantique
  - Construction de contexte pour g√©n√©ration

**Fichiers modifi√©s:**
- `main.py` - Endpoints API documents + initialisation RAGService
- `requirements.txt` - D√©pendances RAG (PyMuPDF, python-docx, chromadb, etc.)

### Frontend (courses)

**Nouveaux fichiers cr√©√©s:**
- `lib/document-types.ts` - Types TypeScript pour documents RAG
- `components/DocumentUpload.tsx` - Composant upload drag & drop + URL

### Variables d'environnement RAG
```
VECTOR_BACKEND=memory|chroma|pinecone|pgvector
DOCUMENT_STORAGE_PATH=/tmp/viralify/documents
```

### Int√©gration RAG avec G√©n√©ration de Cours

**Flux complet:**
1. L'utilisateur uploade des documents via le composant `DocumentUpload`
2. Les documents sont pars√©s, s√©curis√©s et vectoris√©s
3. Lors du preview/generate, les `document_ids` sont envoy√©s √† l'API
4. Le backend r√©cup√®re le contexte RAG via `rag_service.get_context_for_course_generation()`
5. Le `course_planner` inclut ce contexte dans les prompts GPT-4
6. Les cours g√©n√©r√©s sont bas√©s sur le contenu des documents source

**Fichiers modifi√©s pour l'int√©gration:**
- `models/course_models.py` - Ajout `document_ids` et `rag_context` aux requests
- `services/course_planner.py` - Nouveau `_build_rag_section()`, prompts adapt√©s
- `main.py` - Fetch RAG context avant g√©n√©ration outline/cours
- `lib/course-types.ts` - Types TypeScript avec `document_ids`
- `hooks/useCourseGeneration.ts` - Envoi des document_ids dans les appels API

#### RAG 90% Coverage (Am√©lioration Janvier 2026)

**Objectif:** Garantir que 90%+ du contenu g√©n√©r√© provient des documents source.

**Param√®tres optimis√©s:**

| Param√®tre | Avant | Apr√®s | Impact |
|-----------|-------|-------|--------|
| `max_chunks` | 10-15 | **40** | +166% de contexte r√©cup√©r√© |
| `max_chars` | 24000 | **64000** | Documents longs support√©s |
| Instructions prompt | Soft | **Mandatory 90%** | Moins d'hallucinations |

**RAGVerifier - Service de v√©rification (nouveau):**

```
services/presentation-generator/services/rag_verifier.py
```

Analyse le contenu g√©n√©r√© vs les documents source:

| M√©thode | Poids | Description |
|---------|-------|-------------|
| **N-gram overlap** | 40% | D√©tecte les phrases copi√©es directement |
| **Term coverage** | 30% | V√©rifie l'utilisation des termes techniques |
| **Sequence similarity** | 30% | Mesure la similarit√© globale |

**M√©triques disponibles dans la r√©ponse API:**

```json
{
  "script": {
    "rag_verification": {
      "coverage": 0.92,
      "is_compliant": true,
      "summary": "‚úÖ RAG COMPLIANT: 92.0% coverage (threshold: 90%)",
      "potential_hallucinations": 0
    }
  }
}
```

**Logs serveur apr√®s g√©n√©ration:**
```
[PLANNER] ‚úÖ RAG COMPLIANT: 92.3% coverage (threshold: 90%)
```
ou
```
[PLANNER] ‚ö†Ô∏è RAG NON-COMPLIANT: 78.5% coverage (required: 90%) - 3 slides may contain hallucinations
```

**Fichiers modifi√©s (RAG 90%):**
- `services/presentation-generator/services/rag_client.py` - `max_chunks`: 10 ‚Üí 40
- `services/presentation-generator/main.py` - `max_chunks`: 15 ‚Üí 40 (V2 et V3)
- `services/presentation-generator/services/presentation_planner.py` - `max_chars`: 24000 ‚Üí 64000, instructions renforc√©es
- `services/presentation-generator/models/presentation_models.py` - Ajout champ `rag_verification`

**Nouveau fichier:**
- `services/presentation-generator/services/rag_verifier.py` - RAGVerifier, RAGVerificationResult, verify_rag_usage()

---

## Phase 3 - Impl√©mentation (COMPL√âT√âE)

### Backend (media-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/video_editor_models.py` - Mod√®les Pydantic complets
  - SegmentType, TransitionType, SegmentStatus, ProjectStatus (Enums)
  - AudioTrack: piste audio avec volume, fade in/out
  - VideoSegment: segment timeline avec trim, transitions, opacit√©
  - TextOverlay, ImageOverlay: overlays configurables
  - VideoProject: projet complet avec segments et settings
  - Request/Response models pour l'API
- `services/timeline_service.py` - Gestion timeline
  - ProjectRepository: stockage in-memory (PostgreSQL en prod)
  - TimelineService: CRUD projets, segments, overlays
  - _recalculate_timeline: mise √† jour automatique des temps
- `services/segment_manager.py` - Gestion des m√©dias
  - process_upload: traitement vid√©o/audio/image
  - _get_video_duration, _generate_thumbnail via ffprobe/ffmpeg
  - trim_video, extract_audio: utilitaires FFmpeg
  - Validation formats et tailles
- `services/video_merge_service.py` - Rendu final FFmpeg
  - render_project: orchestration du rendu complet
  - _prepare_segment: normalisation r√©solution/fps
  - _image_to_video: conversion slides en vid√©o
  - _concatenate_segments: fusion avec transitions
  - _finalize_video: overlays, musique, encodage final
  - QUALITY_PRESETS: low/medium/high

**Fichiers modifi√©s:**
- `main.py` - +400 lignes pour les endpoints Video Editor API

### Frontend (editor)

**Nouveaux fichiers cr√©√©s:**
- `lib/editor-types.ts` - Types TypeScript
  - Enums: SegmentType, TransitionType, SegmentStatus, ProjectStatus
  - Interfaces: VideoSegment, VideoProject, TextOverlay, ImageOverlay
  - Request/Response types pour l'API
  - Helper functions: formatDuration, getSegmentTypeLabel, etc.
- `hooks/useVideoEditor.ts` - Hook React complet
  - State: project, isLoading, isSaving, isRendering, renderJob
  - Project actions: create, load, update, delete
  - Segment actions: add, upload, update, remove, reorder, split
  - Overlay actions: addTextOverlay, addImageOverlay
  - Render actions: startRender, checkRenderStatus, createPreview
- `components/SegmentItem.tsx` - Composant segment
  - Affichage thumbnail, dur√©e, type
  - Toggle mute audio
  - Drag & drop pour r√©ordonnancement
  - Menu contextuel (edit, mute, remove)
  - Handles de trim visuels
- `components/Timeline.tsx` - Timeline principale
  - R√®gle temporelle avec markers
  - Playhead interactif
  - Drop zones pour r√©ordonnancement
  - Zoom in/out
  - Drag & drop upload
- `components/SegmentProperties.tsx` - Panel propri√©t√©s
  - Trim start/end
  - Volume audio + mute toggle
  - Opacit√©
  - Transitions in/out avec dur√©e
  - Split segment
- `page.tsx` - Page √©diteur compl√®te
  - Modal cr√©ation projet
  - Preview vid√©o
  - Contr√¥les playback (play/pause/stop)
  - Upload m√©dia
  - Export/render avec progression
  - Gestion erreurs

### Acc√®s √† l'√©diteur
- URL: `/dashboard/studio/editor`
- Param√®tres: `?projectId=xxx` ou `?courseJobId=xxx` pour import

---

## Phase 4 - Impl√©mentation (COMPL√âT√âE)

### Backend (media-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/voice_cloning_models.py` - Mod√®les Pydantic complets
  - VoiceProvider, SampleStatus, VoiceProfileStatus (Enums)
  - VoiceSample: √©chantillon audio avec quality metrics
  - VoiceProfile: profil vocal complet avec consent tracking
  - VoiceGenerationSettings: param√®tres de g√©n√©ration
  - Request/Response models pour l'API
- `services/voice_sample_service.py` - Gestion √©chantillons
  - process_sample: upload et validation audio
  - _get_audio_duration via ffprobe
  - _analyze_quality: score qualit√©, bruit, clart√©
  - convert_to_standard_format: normalisation audio
  - VoiceSampleRequirements: specs pour uploads
- `services/voice_cloning_service.py` - Int√©gration ElevenLabs
  - create_cloned_voice: cr√©ation voix via API
  - generate_speech: g√©n√©ration TTS
  - delete_voice: suppression voix
  - get_usage_stats: stats utilisation API
- `services/voice_profile_manager.py` - Orchestration workflow
  - VoiceProfileRepository: stockage in-memory
  - create_profile, get_profile, list_profiles, delete_profile
  - add_sample, remove_sample
  - start_training avec v√©rification consentement
  - generate_speech, preview_voice
  - get_training_requirements

**Fichiers modifi√©s:**
- `main.py` - +250 lignes pour les endpoints Voice Cloning API

### Frontend (voice-clone)

**Nouveaux fichiers cr√©√©s:**
- `lib/voice-types.ts` - Types TypeScript
  - Enums: VoiceProvider, SampleStatus, VoiceProfileStatus
  - Interfaces: VoiceSample, VoiceProfile, VoiceGenerationSettings
  - Request/Response types
  - Helper functions: formatDuration, getStatusLabel, etc.
- `hooks/useVoiceClone.ts` - Hook React complet
  - State: profiles, selectedProfile, requirements
  - Profile actions: create, select, update, delete
  - Sample actions: upload, delete
  - Training actions: startTraining, checkTrainingStatus
  - Generation actions: generateSpeech, previewVoice
- `components/VoiceSampleUpload.tsx` - Upload √©chantillons
  - Drag & drop avec validation format
  - Progress bar dur√©e totale
  - Liste des samples avec quality score
  - Tips d'enregistrement
- `page.tsx` - Page gestion des voix
  - Liste des profils vocaux
  - Cr√©ation profil (nom, genre, accent)
  - Upload samples avec progress
  - Modal consentement pour training
  - Test voice avec audio player
  - Stats utilisation

### Acc√®s au Voice Cloning
- URL: `/dashboard/studio/voice-clone`

### Variables d'environnement
```
ELEVENLABS_API_KEY=your_api_key_here
```

---

## Conventions de code

### Backend (Python/FastAPI)
- Async/await pour toutes les op√©rations I/O
- Pydantic pour la validation des donn√©es
- Timeout de 120s pour les appels OpenAI
- Logging avec `print(..., flush=True)` pour Docker

### Frontend (Next.js/React)
- `useCallback` pour les handlers pass√©s en props
- `useRef` pour les callbacks dans useEffect
- Composants client marqu√©s `'use client'`

---

## Fichiers cl√©s

### Course Generator
- `services/course-generator/services/course_planner.py` - G√©n√©ration du curriculum
- `services/course-generator/services/context_questions.py` - Questions contextuelles
- `services/course-generator/models/course_models.py` - Mod√®les de donn√©es

### Frontend Courses
- `frontend/src/app/dashboard/studio/courses/page.tsx` - Page principale
- `frontend/src/app/dashboard/studio/courses/lib/course-types.ts` - Types TypeScript
- `frontend/src/app/dashboard/studio/courses/components/` - Composants UI

---

## Phase 5 - Impl√©mentation (COMPL√âT√âE)

### Migration pgvector

**Fichiers modifi√©s:**
- `docker-compose.yml` - Image `pgvector/pgvector:pg16`, variable `VECTOR_BACKEND=pgvector`
- `infrastructure/docker/init-pgvector.sql` - Script cr√©ation table + index HNSW
- `services/course-generator/services/vector_store.py` - Classe `PgVectorStore` avec asyncpg
- `services/course-generator/requirements.txt` - D√©pendances asyncpg, pgvector

### Phase 5A: Analytics & Metrics

**Nouveaux fichiers cr√©√©s:**
- `models/analytics_models.py` - Mod√®les Pydantic (CourseMetrics, APIUsageMetrics, etc.)
- `services/analytics_service.py` - Service tracking et agr√©gation

**Endpoints API Analytics:**
- `GET /api/v1/analytics/dashboard` - Dashboard complet
- `GET /api/v1/analytics/user/{user_id}` - R√©sum√© utilisateur
- `GET /api/v1/analytics/api-usage` - Rapport usage API
- `GET /api/v1/analytics/quota/{user_id}` - Quotas utilisateur
- `POST /api/v1/analytics/track` - Track √©v√©nement

**Frontend:**
- `frontend/src/app/dashboard/studio/analytics/` - Dashboard analytics cours

### Phase 5B: Multi-langue (10 langues)

**Langues support√©es:** EN, FR, ES, DE, PT, IT, NL, PL, RU, ZH

**Nouveaux fichiers cr√©√©s:**
- `models/translation_models.py` - Mod√®les (SupportedLanguage, CourseTranslation)
- `services/translation_service.py` - Service traduction via GPT-4o-mini

**Endpoints API Translation:**
- `GET /api/v1/translation/languages` - Langues support√©es
- `POST /api/v1/translation/translate` - Traduire un texte
- `POST /api/v1/translation/translate-batch` - Traduction batch
- `POST /api/v1/translation/detect` - D√©tection de langue
- `POST /api/v1/translation/course/{course_id}` - Traduire un cours complet

### Phase 5C: Mon√©tisation (Stripe + PayPal)

**Plans disponibles:**
| Plan | Prix/mois | Cours/mois | Storage | API Budget |
|------|-----------|------------|---------|------------|
| Free | $0 | 3 | 1 GB | $5 |
| Starter | $19 | 10 | 10 GB | $25 |
| Pro | $49 | 50 | 50 GB | $100 |
| Enterprise | $199 | Illimit√© | 500 GB | $500 |

**Nouveaux fichiers cr√©√©s:**
- `models/billing_models.py` - Mod√®les (Subscription, Payment, Invoice)
- `services/billing_service.py` - Int√©gration Stripe + PayPal

**Endpoints API Billing:**
- `GET /api/v1/billing/plans` - Liste des plans
- `POST /api/v1/billing/checkout` - Cr√©er session checkout
- `GET /api/v1/billing/subscription/{user_id}` - Abonnement actuel
- `POST /api/v1/billing/cancel` - Annuler abonnement
- `POST /api/v1/billing/portal` - Portail de facturation
- `POST /api/v1/billing/webhooks/stripe` - Webhook Stripe
- `POST /api/v1/billing/webhooks/paypal` - Webhook PayPal

**Variables d'environnement:**
```
STRIPE_SECRET_KEY=sk_...
STRIPE_WEBHOOK_SECRET=whsec_...
PAYPAL_CLIENT_ID=...
PAYPAL_CLIENT_SECRET=...
```

### Phase 5D: Collaboration (√âquipes)

**R√¥les disponibles:**
| R√¥le | Permissions |
|------|-------------|
| Owner | Tout (g√©rer √©quipe, billing, supprimer workspace) |
| Admin | G√©rer membres, cr√©er/√©diter/supprimer cours |
| Editor | Cr√©er cours, √©diter ses propres cours |
| Viewer | Voir cours seulement |

**Nouveaux fichiers cr√©√©s:**
- `models/collaboration_models.py` - Mod√®les (Workspace, TeamMember, CourseShare)
- `services/collaboration_service.py` - Service gestion √©quipes

**Endpoints API Collaboration:**
- `POST /api/v1/workspaces` - Cr√©er workspace
- `GET /api/v1/workspaces` - Lister workspaces
- `GET /api/v1/workspaces/{id}` - D√©tails workspace
- `PATCH /api/v1/workspaces/{id}` - Modifier workspace
- `POST /api/v1/workspaces/{id}/invite` - Inviter membre
- `POST /api/v1/workspaces/accept-invitation` - Accepter invitation
- `DELETE /api/v1/workspaces/{id}/members/{member_id}` - Retirer membre
- `PATCH /api/v1/workspaces/{id}/members/{id}/role` - Changer r√¥le
- `POST /api/v1/workspaces/{id}/leave` - Quitter workspace
- `POST /api/v1/courses/{id}/share` - Partager cours
- `GET /api/v1/courses/{id}/shares` - Liste partages
- `GET /api/v1/workspaces/{id}/activity` - Journal d'activit√©

---

## Phase 6 - Enhanced Code & Diagram Generation (IMPL√âMENT√âE)

### Objectifs
Am√©liorer la qualit√© du code et des diagrammes g√©n√©r√©s pour atteindre un niveau professionnel/enterprise-grade.

### Am√©liorations apport√©es

#### 1. TechPromptBuilder - Prompts contextuels dynamiques
Le nouveau `TechPromptBuilder` g√©n√®re des prompts adapt√©s selon:
- **Niveau de l'audience**: D√©butant absolu ‚Üí Expert
- **Domaine tech**: Data Engineering, DevOps, ML, Cybersecurity, etc.
- **Carri√®re cible**: 545+ m√©tiers IT avec contexte sp√©cifique
- **Langages**: 120+ langages avec exemples de style

#### 2. Standards de qualit√© code obligatoires
Tous les codes g√©n√©r√©s respectent:
- Conventions de nommage (descriptif, pas de single letters)
- Structure (max 20 lignes/fonction, max 3 niveaux de nesting)
- Testabilit√© (fonctions pures, DI, pas d'√©tat global)
- Documentation (docstrings, type hints)
- Gestion d'erreurs (exceptions sp√©cifiques, messages significatifs)
- Design patterns appropri√©s

#### 3. DiagramsRenderer - Diagrammes professionnels
Int√©gr√© dans `diagram_generator.py` comme m√©thode **PRIMARY**:
- **Ic√¥nes officielles** AWS, Azure, GCP, Kubernetes, On-Premise
- **Rendu PNG** haute qualit√© avec post-traitement
- **Clustering** logique des composants
- **G√©n√©ration via GPT-4o** pour meilleure pr√©cision
- **D√©tection auto** du cloud provider depuis la description

**Ordre de priorit√© des renderers:**
1. **PRIMARY** - Python Diagrams (architecture, hierarchy, process)
2. **SECONDARY** - Mermaid via Kroki (flowcharts, sequences, mindmaps)
3. **TERTIARY** - PIL fallback

#### 4. Mod√®les de donn√©es exhaustifs

**tech_domains.py** contient:
```python
class CodeLanguage(str, Enum):
    # 120+ langages incluant:
    PYTHON, JAVASCRIPT, GO, RUST, SOLIDITY, QISKIT, CIRQ...

class TechDomain(str, Enum):
    # 80+ domaines incluant:
    DATA_ENGINEERING, MLOPS, DEVOPS, KUBERNETES, QUANTUM_COMPUTING...

class TechCareer(str, Enum):
    # 545+ m√©tiers IT 360¬∞ incluant:
    DATA_LINEAGE_DEVELOPER, MLOPS_ENGINEER, PLATFORM_ENGINEER...
```

#### 5. Visual-Generator Microservice (Architecture)

Le service `visual-generator` est un microservice isol√© qui g√®re la g√©n√©ration de diagrammes:

**Communication:**
```
presentation-generator ‚Üí HTTP POST ‚Üí visual-generator:8003/api/v1/diagrams/generate
```

**Endpoints:**
- `POST /api/v1/diagrams/generate` - G√©n√©ration diagramme depuis description
- `POST /api/v1/diagrams/mermaid` - Rendu Mermaid
- `POST /api/v1/diagrams/detect` - D√©tection besoin diagramme
- `GET /api/v1/diagrams/{filename}` - R√©cup√©ration image
- `DELETE /api/v1/diagrams/{filename}` - Suppression
- `POST /api/v1/diagrams/cleanup` - Nettoyage fichiers anciens

#### 6. Complexit√© des diagrammes par audience

Le syst√®me adapte automatiquement la complexit√© des diagrammes selon l'audience cible:

| Audience | Nodes Max | Caract√©ristiques |
|----------|-----------|------------------|
| **BEGINNER** | 5-7 | Concepts haut-niveau, pas de d√©tails r√©seau, labels courts |
| **SENIOR** | 10-15 | VPCs, caching, load balancers, redundancy, Edge labels |
| **EXECUTIVE** | 6-8 | Flux de valeur, termes business, pas de jargon technique |

**Flux complet de propagation de l'audience:**
```
PresentationPlanner (GPT-4 avec instructions DIAGRAM COMPLEXITY BY AUDIENCE)
    ‚Üì target_audience dans PresentationScript
PresentationCompositor / LangGraphOrchestrator
    ‚Üì target_audience pass√© √† SlideGenerator
SlideGenerator.generate_slide_image(slide, style, target_audience)
    ‚Üì target_audience pass√© √† _render_diagram_slide
DiagramGeneratorService.generate_diagram(..., target_audience)
    ‚Üì Mapping string ‚Üí TargetAudience enum
DiagramsRenderer.generate_and_render(audience=TargetAudience.SENIOR)
    ‚Üì HTTP POST avec audience + cheat_sheet
visual-generator:8003/api/v1/diagrams/generate
    ‚Üì Prompt GPT-4o avec AUDIENCE_INSTRUCTIONS + DIAGRAMS_CHEAT_SHEET
G√©n√©ration code Python Diagrams ‚Üí Ex√©cution Graphviz ‚Üí PNG
```

**DIAGRAMS_CHEAT_SHEET:**
Liste exhaustive des imports valides pour emp√™cher les hallucinations du LLM:
- √âvite les imports inexistants (ex: `from diagrams.aws.compute import NonExistentService`)
- Couvre: AWS, Azure, GCP, Kubernetes, On-Premise, Programming, SaaS, Generic

### Architecture

```
services/presentation-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ tech_domains.py           # Enums: CodeLanguage, TechDomain, TechCareer
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ tech_prompt_builder.py    # Construction prompts contextuels
    ‚îú‚îÄ‚îÄ presentation_planner.py   # Int√©gration du prompt builder + DIAGRAM COMPLEXITY
    ‚îú‚îÄ‚îÄ slide_generator.py        # Param√®tre target_audience ajout√©
    ‚îú‚îÄ‚îÄ diagram_generator.py      # Client HTTP vers visual-generator + audience mapping
    ‚îú‚îÄ‚îÄ presentation_compositor.py # Passage target_audience depuis script
    ‚îú‚îÄ‚îÄ langgraph_orchestrator.py # Passage target_audience depuis script
    ‚îî‚îÄ‚îÄ agents/
        ‚îî‚îÄ‚îÄ visual_sync_agent.py  # Propagation target_audience

services/visual-generator/         # MICROSERVICE ISOL√â (Port 8003)
‚îú‚îÄ‚îÄ main.py                       # FastAPI avec endpoints diagrammes
‚îú‚îÄ‚îÄ Dockerfile                    # Graphviz + d√©pendances lourdes
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ visual_models.py          # DiagramType, DiagramStyle, RenderFormat
‚îî‚îÄ‚îÄ renderers/
    ‚îú‚îÄ‚îÄ diagrams_renderer.py      # Python Diagrams + GPT-4o + audience/cheat_sheet
    ‚îú‚îÄ‚îÄ mermaid_renderer.py       # Mermaid via Kroki (PRIMARY) + mermaid.ink (FALLBACK)
    ‚îî‚îÄ‚îÄ matplotlib_renderer.py    # Charts de donn√©es

#### 7. Kroki Self-Hosted (Diagram Rendering)

Le rendu Mermaid utilise **Kroki self-hosted** comme renderer PRIMARY avec fallback vers mermaid.ink:

**Avantages Kroki:**
- Self-hosted = pas de d√©pendance externe en production
- Privacy: les diagrammes restent dans l'infrastructure
- Supporte 20+ types de diagrammes (Mermaid, PlantUML, D2, GraphViz, etc.)
- Fiabilit√©: pas de rate limiting externe

**Ordre de priorit√©:**
1. **PRIMARY**: Kroki self-hosted (`http://kroki:8000`)
2. **FALLBACK**: mermaid.ink public API (si Kroki indisponible)

**Configuration:**
```python
# mermaid_renderer.py
KROKI_URL = os.getenv("KROKI_URL", "http://kroki:8000")
USE_KROKI = os.getenv("USE_KROKI", "true").lower() == "true"
```

**Docker Compose:**
```yaml
kroki:
  image: yuzutech/kroki
  container_name: viralify-kroki
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
```

#### 8. S√©curit√© - Validation AST du code g√©n√©r√©

Le `DiagramsRenderer` ex√©cute du code Python g√©n√©r√© par GPT-4o. Pour pr√©venir les attaques par injection de code, un validateur AST (`CodeSecurityValidator`) analyse le code AVANT ex√©cution:

**Protections impl√©ment√©es:**

| Type | √âl√©ments bloqu√©s |
|------|------------------|
| **Imports dangereux** | `os`, `subprocess`, `sys`, `socket`, `requests`, `pickle`, etc. |
| **Fonctions dangereuses** | `exec()`, `eval()`, `open()`, `__import__()`, `getattr()` |
| **Attributs dunder** | `__class__`, `__bases__`, `__subclasses__`, `__globals__` |
| **Imports autoris√©s** | UNIQUEMENT `diagrams.*` |

**Flux de validation:**
```
Code g√©n√©r√© par GPT-4o
    ‚Üì
CodeSecurityValidator.validate(code)
    ‚Üì AST parsing
    ‚Üì Import whitelist check
    ‚Üì Blocked functions check
    ‚Üì Dangerous attributes check
    ‚Üì
is_safe = True ‚Üí Ex√©cution autoris√©e
is_safe = False ‚Üí REJET + log s√©curit√©
```

**Exemple d'attaque bloqu√©e:**
```python
# GPT pourrait g√©n√©rer (accidentellement ou par prompt injection):
import os
os.system("rm -rf /")  # ‚ùå BLOQU√â: "SECURITY: Blocked import 'os'"

# ou
exec("malicious_code")  # ‚ùå BLOQU√â: "SECURITY: Blocked function 'exec()'"
```

### Fichiers cr√©√©s/modifi√©s

**Nouveaux fichiers:**
- `models/tech_domains.py` - 545+ m√©tiers, 80+ domaines, 120+ langages
- `services/tech_prompt_builder.py` - Construction de prompts dynamiques
- `services/visual-generator/main.py` - Microservice FastAPI
- `services/visual-generator/Dockerfile` - Image avec Graphviz

**Fichiers modifi√©s (Phase 6 + audience + career):**
- `services/diagram_generator.py` - Client HTTP + DIAGRAMS_CHEAT_SHEET + audience mapping + **career focus**
- `services/presentation_planner.py` - DIAGRAM COMPLEXITY BY AUDIENCE instructions
- `services/slide_generator.py` - Param√®tres `target_audience` + `target_career`
- `services/presentation_compositor.py` - Passage `target_audience` + `target_career`
- `services/langgraph_orchestrator.py` - Passage `target_audience` + `target_career`
- `services/agents/visual_sync_agent.py` - Propagation `target_audience` + `target_career`
- `renderers/diagrams_renderer.py` - Audience instructions + cheat_sheet + **CodeSecurityValidator** (AST validation)
- `models/presentation_models.py` - Champ `target_career` ajout√© √† `PresentationScript` et `GeneratePresentationRequest`
- `models/tech_domains.py` - `DiagramFocus` enum, `CAREER_DIAGRAM_FOCUS_MAP`, `DIAGRAM_FOCUS_INSTRUCTIONS`
- `renderers/mermaid_renderer.py` - Kroki self-hosted (PRIMARY) + mermaid.ink (FALLBACK)
- `docker-compose.prod.yml` - Services visual-generator + kroki ajout√©s
- `docker-compose.yml` - Service kroki ajout√©

#### 9. DiagramFocus - Diff√©renciation par carri√®re

Le syst√®me adapte la **perspective** des diagrammes selon la carri√®re cible (545+ m√©tiers):

**Principe:**
- Un Data Engineer et un Cloud Architect regardent le m√™me syst√®me diff√©remment
- Le Data Engineer veut voir pipelines, ETL, data lakes
- L'Architect veut voir VPCs, load balancers, zones de disponibilit√©

**DiagramFocus Enum:**

| Focus | Exemple de carri√®res | Ce qui est montr√© |
|-------|---------------------|-------------------|
| **CODE** | Software Developer, Backend Engineer | APIs, services, microservices, queues |
| **INFRASTRUCTURE** | Cloud Architect, Platform Engineer | VPCs, load balancers, scaling, HA |
| **DATA** | Data Engineer, Analytics Engineer | Pipelines, ETL/ELT, warehouses, lakes |
| **ML_PIPELINE** | ML Engineer, MLOps Engineer | Feature stores, model serving, training |
| **SECURITY** | Security Engineer, CISO | Zones, firewalls, IAM, encryption |
| **NETWORK** | Network Engineer, SRE | Topology, routing, DNS, CDN |
| **DATABASE** | DBA, Database Architect | Replication, sharding, HA, backups |
| **BUSINESS** | CTO, VP Engineering | Value flow, ROI, high-level view |
| **QA_TESTING** | QA Engineer, Test Lead | Test pyramid, CI/CD, environments |
| **EMBEDDED** | Firmware Engineer, IoT Developer | Hardware, sensors, protocols |

**API Usage:**
```python
# GeneratePresentationRequest
{
    "topic": "Building a data pipeline with Apache Kafka",
    "target_audience": "senior developers",
    "target_career": "data_engineer"  # NEW: diff√©rencie les diagrammes
}
```

**Flux de propagation:**
```
GeneratePresentationRequest.target_career
    ‚Üì Stock√© dans PresentationScript.target_career
PresentationCompositor / LangGraphOrchestrator
    ‚Üì target_career pass√© √† SlideGenerator
SlideGenerator.generate_slide_image(slide, style, target_audience, target_career)
    ‚Üì target_career pass√© √† _render_diagram_slide
DiagramGeneratorService.generate_diagram(..., target_career)
    ‚Üì Parsing TechCareer enum + get_diagram_instructions_for_career()
DiagramsRenderer._build_enhanced_description(career=TechCareer.DATA_ENGINEER)
    ‚Üì Instructions sp√©cifiques ajout√©es au prompt GPT-4o
```

### D√©pendances

```
# visual-generator/requirements.txt
diagrams>=0.23.4
fastapi
uvicorn
openai
pillow

# System requirement (dans Dockerfile visual-generator)
# Graphviz doit √™tre install√©:
# Ubuntu: apt-get install graphviz graphviz-dev
# macOS: brew install graphviz
# Windows: choco install graphviz
```

### Variables d'environnement

```
# presentation-generator
VISUAL_GENERATOR_URL=http://visual-generator:8003

# visual-generator
OPENAI_API_KEY=sk-...
OUTPUT_DIR=/tmp/viralify/diagrams
KROKI_URL=http://kroki:8000
USE_KROKI=true
```

---

## SSVS - Synchronisation Audio-Vid√©o S√©mantique

### SSVS Algorithms (Impl√©ment√©)

Le syst√®me SSVS (Semantic Slide-Voiceover Synchronization) aligne pr√©cis√©ment l'audio et la vid√©o en utilisant l'analyse s√©mantique plut√¥t qu'une distribution proportionnelle simple.

**Architecture:**
```
services/presentation-generator/services/sync/
‚îú‚îÄ‚îÄ __init__.py                    # Exports publics
‚îú‚îÄ‚îÄ ssvs_algorithm.py              # SSVSSynchronizer principal
‚îú‚îÄ‚îÄ ssvs_calibrator.py             # Calibration multi-niveau
‚îî‚îÄ‚îÄ diagram_synchronizer.py        # Extension pour diagrammes
```

**Composants principaux:**

| Classe | R√¥le |
|--------|------|
| `SSVSSynchronizer` | Alignement s√©mantique slides ‚Üî voiceover |
| `SSVSCalibrator` | Correction des 5 sources de d√©synchronisation |
| `DiagramAwareSynchronizer` | Focus sur √©l√©ments de diagramme |
| `SemanticEmbeddingEngine` | Embeddings TF-IDF ou Sentence-BERT |
| `FocusAnimationGenerator` | G√©n√©ration keyframes d'animation |

### SSVS Calibrator (Janvier 2026)

Le calibrateur corrige **5 sources de d√©synchronisation audio-vid√©o:**

| Source | Offset par d√©faut | Description |
|--------|-------------------|-------------|
| **Global offset** | -300ms | D√©calage g√©n√©ral voix/image |
| **STT latency** | -50ms | Latence de transcription |
| **Semantic anticipation** | -150ms | Anticiper le slide avant le mot |
| **Transition duration** | 200ms | Temps de transition visuelle |
| **Visual inertia** | Variable | L'≈ìil a besoin de temps pour se fixer |

**Presets disponibles:**

| Preset | Usage | Caract√©ristiques |
|--------|-------|------------------|
| `default` | Standard | Offsets moyens |
| `fast_speech` | Speakers rapides | Anticipation r√©duite |
| `slow_speech` | Speakers lents | Plus de temps par slide |
| `technical_content` | Code, diagrammes | Slides plus longues |
| `simple_slides` | Texte simple | Transitions rapides |
| `live_presentation` | Style conf√©rence | Dynamique |
| `training_course` | **Formation Viralify** | Offset -400ms, anticipation -200ms |

**Fichiers:**
- `services/sync/ssvs_calibrator.py` - CalibrationConfig, SSVSCalibrator, CalibrationPresets
- `services/timeline_builder.py` - Int√©gration avec `calibration_preset` parameter

**Usage:**
```python
builder = TimelineBuilder(
    sync_method=SyncMethod.SSVS,
    calibration_preset="training_course"  # Preset optimis√© pour Viralify
)
```

### SSVS Embedding Engines (Janvier 2026)

Backends d'embedding configurables pour la synchronisation s√©mantique.

**Configuration:** `SSVS_EMBEDDING_BACKEND=auto|minilm|bge-m3|tfidf`

| Backend | Mod√®le | Dimensions | Taille | Qualit√© | Multilangue |
|---------|--------|------------|--------|---------|-------------|
| **minilm** | all-MiniLM-L6-v2 | 384 | ~80MB | ‚≠ê‚≠ê‚≠ê | üü° |
| **bge-m3** | BAAI/bge-m3 | 1024 | ~2GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ 100+ |
| **tfidf** | TF-IDF (local) | Variable | 0 | ‚≠ê‚≠ê | üü° |
| **auto** | MiniLM ‚Üí TF-IDF | - | - | Adaptatif | - |

**Ordre de priorit√© (mode auto):**
1. MiniLM (si sentence-transformers install√©)
2. TF-IDF (fallback sans d√©pendances)

**Architecture:**
```
services/sync/
‚îú‚îÄ‚îÄ embedding_engine.py        # NOUVEAU - Factory + backends
‚îÇ   ‚îú‚îÄ‚îÄ EmbeddingEngineBase (ABC)
‚îÇ   ‚îú‚îÄ‚îÄ TFIDFEmbeddingEngine
‚îÇ   ‚îú‚îÄ‚îÄ SentenceTransformerEngine (MiniLM/BGE-M3)
‚îÇ   ‚îî‚îÄ‚îÄ EmbeddingEngineFactory
‚îú‚îÄ‚îÄ ssvs_algorithm.py          # SSVSSynchronizer (modifi√©)
‚îî‚îÄ‚îÄ __init__.py                # Exports mis √† jour
```

**D√©pendances (optionnelles):**
```
# requirements.txt
sentence-transformers>=2.2.0  # Pour MiniLM et BGE-M3
torch>=2.0.0                  # CPU version
```

**Usage:**
```python
# Via SSVSSynchronizer
sync = SSVSSynchronizer(embedding_backend="minilm")

# Via factory directe
from services.sync import EmbeddingEngineFactory
engine = EmbeddingEngineFactory.create("auto")
```

### SSVS Sync Anchors (Janvier 2026)

Les **sync anchors** sont des contraintes dures qui forcent l'alignement √† des points pr√©cis.

**Format dans le voiceover:**
```
[SYNC:SLIDE_2] Passons maintenant au deuxi√®me sujet...
```

**Comportement:**
- L'anchor `[SYNC:SLIDE_2]` FORCE le slide 2 √† commencer exactement √† ce mot
- L'algorithme partitionne le probl√®me aux points d'anchor
- Chaque partition est r√©solue ind√©pendamment par DP

**Flux d'impl√©mentation:**
```
[SYNC:SLIDE_2] dans voiceover
       ‚Üì
_find_sync_anchors() extrait les anchors (timeline_builder.py)
       ‚Üì
_convert_to_ssvs_anchors() convertit en SSVSSyncAnchor
       ‚Üì
synchronize_with_anchors() utilise comme CONTRAINTE DURE
       ‚Üì
_create_anchor_partitions() divise le probl√®me DP
       ‚Üì
R√©sultat: slide align√© exactement √† l'anchor
```

**Dataclass SyncAnchor:**
```python
@dataclass
class SyncAnchor:
    slide_index: int      # Slide concern√©
    timestamp: float      # Timestamp cible (secondes)
    segment_index: int    # Segment vocal correspondant
    anchor_type: str      # SLIDE, CODE, DIAGRAM
    anchor_id: str        # "SLIDE_2"
    tolerance_ms: float   # Tol√©rance (d√©faut: 500ms)
```

**R√©sultat avec anchor_used:**
```python
@dataclass
class SynchronizationResult:
    # ... existing fields ...
    anchor_used: Optional[SyncAnchor] = None  # Si ancr√©
```

**Test de validation:**
```
Sans anchors:  Slide 2: 5.5s - 9.0s
Avec anchor:   Slide 2: 5.5s - 9.0s [ANCHORED] ‚Üê Contrainte respect√©e
```

**Fichiers modifi√©s:**
- `services/sync/ssvs_algorithm.py` - SyncAnchor, synchronize_with_anchors()
- `services/timeline_builder.py` - _convert_to_ssvs_anchors(), _find_segment_for_timestamp()
- `services/sync/__init__.py` - Export SyncAnchor

---

## Notes importantes

- Les volumes Docker persistants sont configur√©s pour `/tmp/viralify/videos`, `/tmp/presentations`, `/app/output`, `/tmp/viralify/diagrams`
- Les timeouts OpenAI sont fix√©s √† 120s avec 2 retries
- Le frontend n√©cessite un rebuild Docker apr√®s modification des fichiers
- pgvector utilise l'index HNSW pour la recherche vectorielle rapide
- Les webhooks Stripe/PayPal doivent √™tre configur√©s dans les dashboards respectifs
- **Graphviz** est requis pour la g√©n√©ration de diagrammes avec la librairie Diagrams
- **visual-generator** est un microservice isol√© (port 8003) - les d√©pendances lourdes (Graphviz, Diagrams) y sont centralis√©es
- La complexit√© des diagrammes s'adapte automatiquement selon `target_audience` de la pr√©sentation
- **Kroki** est self-hosted pour le rendu Mermaid (privacy + reliability), avec fallback vers mermaid.ink si indisponible
