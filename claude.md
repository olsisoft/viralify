# Viralify - Claude Code Context

---

## R√®gles de travail Claude

### Processus obligatoire avant tout changement de code

1. **Comprendre** - Lire les fichiers concern√©s, ne jamais supposer
2. **Expliquer** - D√©crire le probl√®me tel que compris
3. **Proposer** - Pr√©senter 2-3 approches avec pros/cons
4. **Valider** - Attendre l'approbation explicite de l'utilisateur
5. **Impl√©menter** - √âcrire le code seulement apr√®s validation
6. **Montrer** - Afficher le diff avant de commit
7. **Confirmer** - Attendre l'approbation pour commit/push

### Ne jamais faire sans validation

- Changements architecturaux
- Ajout de d√©pendances
- Modification de fichiers de config (docker-compose, etc.)
- Suppression de code existant
- Refactoring non demand√©

### Session tracking

**Dernier commit:** `2cc39b8` - fix: handle empty LLM responses with retry logic
**Date:** 2026-01-29
**Travail en cours:** Phase 9 - Lecture Editor & Job Management

### RAG Verifier v6 - Phases Compl√©t√©es

| Phase | Fonctionnalit√© | Status |
|-------|---------------|--------|
| Phase 1 | E5-Large Multilingual embeddings | ‚úÖ |
| Phase 2 | WeaveGraph concept graph + pgvector | ‚úÖ |
| Phase 3 | Resonate Match + auto-extraction concepts | ‚úÖ |

**Flux complet:**
1. User uploade document ‚Üí SourceLibrary envoie sourceIds
2. RAG context re√ßu ‚Üí concepts extraits en background (WeaveGraphBuilder)
3. Concepts stock√©s dans pgvector avec embeddings E5-large
4. Query expansion via graph de concepts (+2-5% boost)
5. Resonance propagation multi-hop (decay=0.7, depth=3)
6. Boost combin√© appliqu√© au coverage score

### Phase 8B: Viralify Diagrams (IMPL√âMENT√â + GRAPHVIZ HYBRID)

Librairie Python de g√©n√©ration de diagrammes professionnels pour contenu vid√©o.

**Repository:** `olsisoft/viralify-diagrams` (GitHub - pouss√©)
**Local:** `C:\Users\njomi\OneDrive\Documents\projects\viralify-diagrams`

**Fonctionnalit√©s impl√©ment√©es:**
- **Syst√®me de th√®mes** avec 6 th√®mes int√©gr√©s (dark, light, gradient, ocean, corporate, neon)
- **Th√®mes personnalis√©s** via JSON (upload utilisateur support√©)
- **Moteurs de layout (simples + Graphviz hybrid):**
  - GridLayout: Grille uniforme
  - HorizontalLayout: Flow gauche-droite (pipelines, data flows)
  - VerticalLayout: Flow haut-bas (hi√©rarchies, architectures)
  - RadialLayout: Hub central avec satellites (API, √©toile)
  - **GraphvizLayout** (NOUVEAU): Layout hybrid avec 6 algorithmes Graphviz
    - `dot`: Hi√©rarchique (DAGs, flowcharts) - **recommand√©**
    - `neato`: Spring model (graphes non-dirig√©s)
    - `fdp`: Force-directed (grands graphes)
    - `sfdp`: Scalable (100k+ nodes)
    - `circo`: Circulaire
    - `twopi`: Radial tree
  - **auto_layout()**: S√©lection automatique du meilleur algorithme
- **3 modes d'export:**
  - SVGExporter: SVG statique avec groupes nomm√©s pour animation externe
  - AnimatedSVGExporter: SVG avec animations CSS int√©gr√©es
  - PNGFrameExporter: Frames PNG pour composition vid√©o (avec FFmpeg)
- **G√©n√©ration de narration:**
  - DiagramNarrator avec 4 styles (educational, professional, casual, technical)
  - Export SRT (sous-titres), SSML (TTS), JSON
  - Synchronisation avec timeline d'animation
- **Optimisation vid√©o:**
  - Auto-simplification (max 8-10 nodes)
  - 7 formes de nodes (rectangle, rounded, circle, diamond, hexagon, cylinder, cloud)
  - Clustering visuel avec labels
  - Animation order bas√© sur topologie (BFS depuis sources)

**Approche Hybride Graphviz (50+ composants):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     HYBRID APPROACH                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. GRAPHVIZ calcule les positions optimales               ‚îÇ
‚îÇ     - Minimisation des croisements d'ar√™tes                ‚îÇ
‚îÇ     - Clustering automatique                                ‚îÇ
‚îÇ     - Support 100k+ nodes avec sfdp                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  2. VIRALIFY-DIAGRAMS applique le rendu                    ‚îÇ
‚îÇ     - Th√®mes professionnels (dark, light, gradient...)     ‚îÇ
‚îÇ     - Export SVG/PNG avec animations                        ‚îÇ
‚îÇ     - Couleurs coh√©rentes avec les slides                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Licence:** MIT

**Structure:**
```
viralify-diagrams/
‚îú‚îÄ‚îÄ viralify_diagrams/
‚îÇ   ‚îú‚îÄ‚îÄ core/           # Diagram, Node, Edge, Cluster, Theme, ThemeManager
‚îÇ   ‚îú‚îÄ‚îÄ layouts/        # BaseLayout, Grid, Horizontal, Vertical, Radial, GraphvizLayout
‚îÇ   ‚îú‚îÄ‚îÄ exporters/      # SVGExporter, AnimatedSVGExporter, PNGFrameExporter
‚îÇ   ‚îî‚îÄ‚îÄ narration/      # DiagramNarrator, NarrationScript, NarrationSegment
‚îú‚îÄ‚îÄ examples/           # basic_diagram.py, custom_theme.py, graphviz_layout_example.py
‚îú‚îÄ‚îÄ tests/              # pytest tests (test_graphviz_layout.py)
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ requirements.txt    # pygraphviz>=1.11
```

**Installation:**
```bash
# System dependency (required for pygraphviz)
apt-get install graphviz graphviz-dev  # Ubuntu/Debian
brew install graphviz                   # macOS

pip install viralify-diagrams
pip install viralify-diagrams[png]  # avec support export PNG
```

**Usage basique:**
```python
from viralify_diagrams import Diagram, HorizontalLayout, SVGExporter

diagram = Diagram(title="API Architecture", theme="dark")
diagram.add_node("api", "API Gateway")
diagram.add_node("db", "PostgreSQL")
diagram.add_edge("api", "db")

layout = HorizontalLayout()
diagram = layout.layout(diagram)

exporter = SVGExporter()
svg = exporter.export(diagram, "output.svg")
```

**Usage Graphviz (50+ composants):**
```python
from viralify_diagrams import Diagram, GraphvizLayout, auto_layout, SVGExporter

diagram = Diagram(title="Microservices", theme="dark", width=1920, height=1080)
# ... add 50+ nodes and edges ...

# Option 1: Explicit algorithm
layout = GraphvizLayout(algorithm="dot", rankdir="TB")
diagram = layout.layout(diagram)

# Option 2: Auto-select best algorithm
diagram = auto_layout(diagram)  # Recommends dot/sfdp based on graph

exporter = SVGExporter()
exporter.export(diagram, "microservices.svg")
```

**Int√©gration dans Viralify (presentation-generator):**
```env
# docker-compose.yml
USE_VIRALIFY_DIAGRAMS=true  # Active le rendu avec th√®mes
```

Le `SlideGeneratorService` utilise automatiquement `ViralifyDiagramService` pour:
- Diagrammes avec couleurs matchant le th√®me de la pr√©sentation
- Layout Graphviz pour les diagrammes complexes
- Fallback vers `DiagramGeneratorService` si erreur

---

## Project Overview

Viralify est une plateforme de cr√©ation de contenu viral pour les r√©seaux sociaux, avec un focus particulier sur la g√©n√©ration automatis√©e de cours vid√©o √©ducatifs.

### Niche Tech - Plateforme pour toute la Tech IT

Cette plateforme est con√ßue pour couvrir **l'ensemble de l'√©cosyst√®me IT**, incluant:
- **545+ m√©tiers** tech (Data Engineer, MLOps Engineer, Cloud Architect, etc.)
- **80+ domaines** (Data Engineering, DevOps, Cybersecurity, Quantum Computing, etc.)
- **120+ langages** de programmation (Python, Go, Rust, Solidity, Qiskit, etc.)

Les agents g√©n√®rent du contenu adapt√© √† chaque profil, niveau et domaine technique.

## Architecture

### Services principaux
- **frontend** (Next.js) - Port 3000
- **api-gateway** (Spring Boot) - Port 8080
- **course-generator** (FastAPI) - Port 8007
- **presentation-generator** (FastAPI) - Port 8006
- **media-generator** (FastAPI) - Port 8004
- **visual-generator** (FastAPI) - Port 8003 (microservice diagrammes)
- **vqv-hallu** (FastAPI) - Port 8009 (validation voiceover TTS)
- **maestro-engine** (FastAPI) - Port 8010 (g√©n√©ration avanc√©e avec calibration 4D)
- **nexus-engine** (FastAPI) - Port 8011 (g√©n√©ration de code p√©dagogique)
- **diagrams-generator** (FastAPI) - Port 8012 (g√©n√©ration de diagrammes viralify-diagrams)

### Services auxiliaires (non d√©ploy√©s en prod)
- **coaching-service** - Service de coaching personnalis√©
- **trend-analyzer** - Analyse des tendances
- **analytics-service** - Analytics et m√©triques
- **notification-service** - Notifications push/email
- **practice-agent** - Agent de pratique interactive

### Infrastructure
- PostgreSQL + pgvector (embeddings), Redis (jobs, cache), RabbitMQ, Elasticsearch
- **Kroki** - Self-hosted diagram rendering (Mermaid, PlantUML, D2, GraphViz)
- Docker Compose pour l'orchestration
- **Kubernetes** - Manifests disponibles dans `/k8s` pour d√©ploiement cloud

---

## Course Generator - Roadmap

### Phase 1: √âl√©ments de le√ßon adaptatifs + Quiz (ACTUELLE)

#### Objectifs
1. **Option A** - Mapping des √©l√©ments par cat√©gorie de profil
2. **Option C** - Suggestion IA des √©l√©ments selon le sujet
3. **Quiz obligatoires** - Tous les cours incluent des √©valuations

#### √âl√©ments par cat√©gorie

| Cat√©gorie | √âl√©ments sp√©cifiques |
|-----------|---------------------|
| **Tech** | `code_demo`, `terminal_output`, `architecture_diagram`, `debug_tips` |
| **Business** | `case_study`, `framework_template`, `roi_metrics`, `action_checklist`, `market_analysis` |
| **Health** | `exercise_demo`, `safety_warning`, `body_diagram`, `progression_plan`, `rest_guidance` |
| **Creative** | `before_after`, `technique_demo`, `tool_tutorial`, `creative_exercise`, `critique_section` |
| **Education** | `memory_aid`, `practice_problem`, `multiple_explanations`, `summary_card` |
| **Lifestyle** | `daily_routine`, `reflection_exercise`, `goal_setting`, `habit_tracker`, `milestone` |

#### √âl√©ments communs (tous les cours)

| √âl√©ment | Description | Obligatoire |
|---------|-------------|-------------|
| `concept_intro` | Introduction du concept principal | Oui |
| `voiceover` | Narration explicative | Oui |
| `curriculum_slide` | Position dans le cours | Oui |
| `conclusion` | R√©capitulatif des points cl√©s | Oui |
| `quiz_evaluation` | Quiz interactif | **Oui** |

#### Configuration des Quiz

- **Format**: Style Udemy (QCM, Vrai/Faux, association, r√©ponses courtes)
- **Fr√©quence**: Configurable par l'utilisateur au frontend
  - Par lecture
  - Par section
  - √Ä la fin du cours uniquement
  - Personnalis√© (toutes les N lectures)
- **G√©n√©ration**: L'IA g√©n√®re les questions bas√©es sur le contenu de la le√ßon

#### Suggestion IA (Option C)

L'IA analyse le sujet, la description et le contexte pour:
1. D√©tecter automatiquement la cat√©gorie si non sp√©cifi√©e
2. Sugg√©rer les √©l√©ments les plus pertinents avec score de pertinence
3. Proposer des √©l√©ments additionnels bas√©s sur le sujet sp√©cifique

---

### Phase 2: RAG - Documentation Source (COMPL√âT√âE + INT√âGR√âE + 90% GARANTI)

#### Objectifs
L'utilisateur peut uploader des documents comme source de contenu pour la g√©n√©ration de cours.
Le syst√®me garantit que **90% minimum** du contenu g√©n√©r√© provient des documents source.

#### Formats support√©s
- PDF (via PyMuPDF)
- Word (DOCX, DOC)
- PowerPoint (PPTX, PPT)
- Texte (TXT, MD)
- Excel (XLSX, XLS, CSV)
- URLs/pages web
- Vid√©os YouTube (transcription via youtube-transcript-api)

#### S√©curit√© des documents (Impl√©ment√©e)
- **Validation du type MIME** avec python-magic
- **V√©rification extension vs contenu** r√©el
- **D√©tection de macros** (VBA dans Office)
- **D√©tection d'objets embarqu√©s** dangereux
- **Limite de taille** par type de fichier (50 MB max)
- **D√©tection de patterns malicieux** (injection, scripts)
- **Protection zip bomb** (ratio de compression)
- **Sanitization des noms de fichiers**

#### Architecture RAG (Impl√©ment√©e)
```
services/course-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ document_models.py     # Document, DocumentChunk, RAGQuery models
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ security_scanner.py    # Validation s√©curit√© compl√®te
    ‚îú‚îÄ‚îÄ document_parser.py     # Extraction multi-format
    ‚îú‚îÄ‚îÄ vector_store.py        # Embeddings OpenAI + ChromaDB/Memory
    ‚îî‚îÄ‚îÄ retrieval_service.py   # Orchestration RAG compl√®te
```

#### Endpoints API Documents
- `POST /api/v1/documents/upload` - Upload fichier
- `POST /api/v1/documents/upload-url` - Import URL/YouTube
- `GET /api/v1/documents` - Liste documents
- `GET /api/v1/documents/{id}` - D√©tails document
- `DELETE /api/v1/documents/{id}` - Supprimer
- `POST /api/v1/documents/query` - Recherche RAG
- `GET /api/v1/documents/context/{course_id}` - Contexte pour g√©n√©ration

#### Frontend Components
- `lib/document-types.ts` - Types TypeScript
- `components/DocumentUpload.tsx` - Upload drag & drop + URL

---

### Phase 3: √âdition Vid√©o Utilisateur (COMPL√âT√âE)

#### Objectifs
L'utilisateur peut modifier la vid√©o de cours g√©n√©r√©e et ajouter ses propres enregistrements.

#### Fonctionnalit√©s
- Visualisation de la timeline du cours
- Remplacement de segments vid√©o
- Ajout d'enregistrements personnels (webcam, screen recording)
- Ajustement de la synchronisation audio/vid√©o
- Insertion de slides personnalis√©es
- Trim/cut des sections
- Transitions entre segments
- Overlays texte et image
- Export vid√©o final

#### Architecture Backend (media-generator)
```
services/media-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ video_editor_models.py    # Mod√®les Pydantic (VideoProject, VideoSegment, etc.)
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ timeline_service.py       # Gestion timeline + ProjectRepository
    ‚îú‚îÄ‚îÄ segment_manager.py        # Upload et traitement des m√©dias
    ‚îî‚îÄ‚îÄ video_merge_service.py    # Rendu FFmpeg final
```

#### Endpoints API Video Editor
- `POST /api/v1/editor/projects` - Cr√©er un projet
- `GET /api/v1/editor/projects` - Lister les projets
- `GET /api/v1/editor/projects/{id}` - D√©tails projet
- `DELETE /api/v1/editor/projects/{id}` - Supprimer projet
- `PATCH /api/v1/editor/projects/{id}/settings` - Param√®tres projet
- `POST /api/v1/editor/projects/{id}/segments` - Ajouter segment
- `POST /api/v1/editor/projects/{id}/segments/upload` - Upload m√©dia
- `PATCH /api/v1/editor/projects/{id}/segments/{segId}` - Modifier segment
- `DELETE /api/v1/editor/projects/{id}/segments/{segId}` - Supprimer segment
- `POST /api/v1/editor/projects/{id}/segments/reorder` - R√©ordonner
- `POST /api/v1/editor/projects/{id}/segments/{segId}/split` - Diviser segment
- `POST /api/v1/editor/projects/{id}/overlays/text` - Overlay texte
- `POST /api/v1/editor/projects/{id}/overlays/image` - Overlay image
- `POST /api/v1/editor/projects/{id}/render` - Lancer le rendu
- `GET /api/v1/editor/render-jobs/{jobId}` - Statut rendu
- `POST /api/v1/editor/projects/{id}/preview` - Preview rapide
- `GET /api/v1/editor/supported-formats` - Formats support√©s

#### Frontend Components (editor)
```
frontend/src/app/dashboard/studio/editor/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ editor-types.ts           # Types TypeScript
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îî‚îÄ‚îÄ useVideoEditor.ts         # Hook React pour l'API
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ Timeline.tsx              # Timeline principale
‚îÇ   ‚îú‚îÄ‚îÄ SegmentItem.tsx           # Item de segment
‚îÇ   ‚îî‚îÄ‚îÄ SegmentProperties.tsx     # Panel propri√©t√©s
‚îî‚îÄ‚îÄ page.tsx                      # Page √©diteur
```

#### Formats support√©s
- **Vid√©o**: mp4, mov, avi, mkv, webm, m4v (max 500 MB)
- **Audio**: mp3, wav, aac, m4a, ogg (max 50 MB)
- **Image**: jpg, jpeg, png, gif, webp (max 10 MB)

---

### Phase 4: Voice Cloning (COMPL√âT√âE)

#### Objectifs
L'utilisateur peut cloner sa voix pour personnaliser la narration des cours.

#### Fonctionnalit√©s
- Upload d'√©chantillons vocaux (minimum 30 secondes)
- Analyse qualit√© audio (bruit, clart√©)
- Entra√Ænement du mod√®le via ElevenLabs API
- G√©n√©ration TTS avec la voix clon√©e
- Ajustement stabilit√©, similarit√©, style
- Preview avant g√©n√©ration compl√®te
- Consentement explicite obligatoire

#### Provider
- **ElevenLabs** - Instant Voice Cloning API
- Mod√®le: eleven_multilingual_v2
- Output: MP3 44.1kHz

#### Architecture Backend (media-generator)
```
services/media-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ voice_cloning_models.py     # VoiceProfile, VoiceSample, etc.
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ voice_sample_service.py     # Upload + validation audio
    ‚îú‚îÄ‚îÄ voice_cloning_service.py    # Int√©gration ElevenLabs
    ‚îî‚îÄ‚îÄ voice_profile_manager.py    # Orchestration workflow
```

#### Endpoints API Voice Cloning
- `POST /api/v1/voice/profiles` - Cr√©er profil vocal
- `GET /api/v1/voice/profiles` - Lister profils
- `GET /api/v1/voice/profiles/{id}` - D√©tails profil
- `DELETE /api/v1/voice/profiles/{id}` - Supprimer profil
- `PATCH /api/v1/voice/profiles/{id}` - Modifier profil
- `POST /api/v1/voice/profiles/{id}/samples` - Upload √©chantillon
- `DELETE /api/v1/voice/profiles/{id}/samples/{sampleId}` - Supprimer √©chantillon
- `POST /api/v1/voice/profiles/{id}/train` - D√©marrer entra√Ænement
- `GET /api/v1/voice/profiles/{id}/training-status` - Statut entra√Ænement
- `POST /api/v1/voice/profiles/{id}/generate` - G√©n√©rer audio
- `POST /api/v1/voice/profiles/{id}/preview` - Preview rapide
- `GET /api/v1/voice/requirements` - Requis pour √©chantillons
- `GET /api/v1/voice/usage` - Stats utilisation API

#### Frontend Components (voice-clone)
```
frontend/src/app/dashboard/studio/voice-clone/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ voice-types.ts              # Types TypeScript
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îî‚îÄ‚îÄ useVoiceClone.ts            # Hook React pour l'API
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ VoiceSampleUpload.tsx       # Upload avec drag & drop
‚îî‚îÄ‚îÄ page.tsx                        # Page gestion des voix
```

#### Requirements √©chantillons
- **Formats**: mp3, wav, m4a, ogg, webm, flac, aac
- **Dur√©e par sample**: 5-300 secondes
- **Dur√©e totale min**: 30 secondes
- **Dur√©e id√©ale**: 60 secondes
- **Taille max**: 50 MB par fichier

#### S√©curit√© & Consentement
- Consentement explicite obligatoire avant entra√Ænement
- Enregistrement IP et timestamp du consentement
- Profils suspendables en cas d'abus

---

## D√©cisions techniques

### Choisies
- [x] √âl√©ments adaptatifs par cat√©gorie (Option A)
- [x] Suggestion IA des √©l√©ments (Option C)
- [x] Quiz obligatoires format Udemy
- [x] Fr√©quence quiz configurable par utilisateur
- [x] Support multi-format documents (Phase 2)
- [x] Validation s√©curit√© documents obligatoire
- [x] Vector store: ChromaDB par d√©faut, InMemory pour dev, architecture extensible
- [x] Embeddings: OpenAI text-embedding-3-small
- [x] Code generation: GPT-4o avec TechPromptBuilder contextuel (Phase 6)
- [x] Diagrammes: Librairie Diagrams (Python) avec ic√¥nes AWS/Azure/GCP (Phase 6)
- [x] Couverture tech: 545+ m√©tiers, 80+ domaines, 120+ langages (Phase 6)
- [x] Multi-provider LLM: 8 providers (OpenAI, Groq, DeepSeek, Mistral, Together, xAI, Ollama, RunPod)
- [x] RAG Verifier v4: E5-large multilingue pour cross-langue (FR/EN)
- [x] Training Logger: Collecte JSONL pour fine-tuning futur
- [x] WeaveGraph: Graphe de concepts pour expansion de requ√™tes RAG (Phase 2)
- [x] Resonate Match: Propagation multi-hop avec decay pour RAG (Phase 3)

### En attente
- [x] Provider de voice cloning: ElevenLabs (Phase 4 compl√©t√©e)
- [x] √âditeur vid√©o: web-based (Phase 3 compl√©t√©e)
- [x] Migration vector store vers pgvector pour production (Phase 5)
- [x] Analytics & Metrics (Phase 5A)
- [x] Multi-langue 10 langues (Phase 5B)
- [x] Mon√©tisation Stripe + PayPal (Phase 5C)
- [x] Collaboration avec √©quipes (Phase 5D)
- [x] Enhanced code/diagram generation (Phase 6 compl√©t√©e)

### RAG Prompt System v2 (Janvier 2026)

**Impl√©ment√©: Option B - Int√©gration Hybride**

Structure "Sandwich" pour maximiser la compliance RAG:
- `RAG_STRICT_HEADER` au D√âBUT du system prompt (primacy effect)
- `VALIDATED_PLANNING_PROMPT` au milieu
- `RAG_STRICT_FOOTER` √† la FIN (recency effect)

**Fichiers modifi√©s:**
- `services/planner/prompts/system_prompts.py` - Ajout `RAG_STRICT_HEADER`, `RAG_STRICT_FOOTER`
- `services/planner/prompts/rag_prompts.py` - Tags `<source_documents>` pour d√©limitation
- `services/presentation_planner.py` - Injection conditionnelle dans system prompt, temperature 0.3

**Logs √† v√©rifier:**
```
[PLANNER] üîí RAG STRICT MODE - Sandwich structure enabled
```

**Option A (future):** Refactoring complet avec `RAGPromptBuilder` - code disponible dans `C:\Users\njomi\Downloads\files (3)\rag_prompt_system\`

---

## Phase 1 - Impl√©mentation (COMPL√âT√âE)

### Backend (course-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/lesson_elements.py` - Mod√®les pour √©l√©ments par cat√©gorie + quiz
- `services/element_suggester.py` - Service IA de suggestion d'√©l√©ments (Option C)
- `services/quiz_generator.py` - G√©n√©rateur de quiz style Udemy

**Fichiers modifi√©s:**
- `models/course_models.py` - Ajout QuizConfigRequest, AdaptiveElementsRequest
- `main.py` - Nouveaux endpoints API

**Nouveaux endpoints API:**
- `GET /api/v1/courses/config/categories` - Liste des cat√©gories
- `GET /api/v1/courses/config/elements/{category}` - √âl√©ments par cat√©gorie
- `POST /api/v1/courses/config/suggest-elements` - Suggestion IA
- `GET /api/v1/courses/config/detect-category` - D√©tection auto cat√©gorie
- `GET /api/v1/courses/config/quiz-options` - Options de quiz

### Frontend (courses)

**Nouveaux fichiers cr√©√©s:**
- `lib/lesson-elements.ts` - Types TypeScript pour √©l√©ments et quiz
- `components/AdaptiveLessonElements.tsx` - Composant √©l√©ments adaptatifs
- `components/QuizConfigPanel.tsx` - Configuration des quiz

**Fichiers modifi√©s:**
- `lib/course-types.ts` - Ajout QuizConfig, AdaptiveElementsConfig
- `page.tsx` - √âtat initial avec quiz et √©l√©ments adaptatifs

---

## Phase 2 - Impl√©mentation (COMPL√âT√âE)

### Backend (course-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/document_models.py` - Mod√®les Document, DocumentChunk, RAG
  - Document: m√©tadonn√©es fichier, statut, chunks
  - DocumentChunk: contenu + embedding pour RAG
  - SecurityScanResult: r√©sultats validation s√©curit√©
  - RAGQueryRequest/Response: requ√™tes de recherche
- `services/security_scanner.py` - Validation s√©curit√© compl√®te
  - Validation MIME type avec libmagic
  - D√©tection macros VBA
  - D√©tection objets embarqu√©s dangereux
  - Protection path traversal et zip bombs
  - Patterns malicieux (scripts, injection)
- `services/document_parser.py` - Extraction multi-format
  - PDF via PyMuPDF
  - DOCX/DOC via python-docx
  - PPTX/PPT via python-pptx
  - XLSX/XLS via openpyxl/xlrd
  - CSV, TXT, Markdown
  - URLs via httpx + BeautifulSoup
  - YouTube via youtube-transcript-api
- `services/vector_store.py` - Embeddings et stockage
  - EmbeddingService: OpenAI text-embedding-3-small
  - ChromaVectorStore: backend ChromaDB
  - InMemoryVectorStore: backend d√©veloppement
  - VectorStoreFactory: abstraction backends
- `services/retrieval_service.py` - Orchestration RAG
  - Upload et processing documents
  - Recherche s√©mantique
  - Construction de contexte pour g√©n√©ration

**Fichiers modifi√©s:**
- `main.py` - Endpoints API documents + initialisation RAGService
- `requirements.txt` - D√©pendances RAG (PyMuPDF, python-docx, chromadb, etc.)

### Frontend (courses)

**Nouveaux fichiers cr√©√©s:**
- `lib/document-types.ts` - Types TypeScript pour documents RAG
- `components/DocumentUpload.tsx` - Composant upload drag & drop + URL

### Variables d'environnement RAG
```
VECTOR_BACKEND=memory|chroma|pinecone|pgvector
DOCUMENT_STORAGE_PATH=/tmp/viralify/documents
```

### Int√©gration RAG avec G√©n√©ration de Cours

**Flux complet:**
1. L'utilisateur uploade des documents via le composant `DocumentUpload`
2. Les documents sont pars√©s, s√©curis√©s et vectoris√©s
3. Lors du preview/generate, les `document_ids` sont envoy√©s √† l'API
4. Le backend r√©cup√®re le contexte RAG via `rag_service.get_context_for_course_generation()`
5. Le `course_planner` inclut ce contexte dans les prompts GPT-4
6. Les cours g√©n√©r√©s sont bas√©s sur le contenu des documents source

**Fichiers modifi√©s pour l'int√©gration:**
- `models/course_models.py` - Ajout `document_ids` et `rag_context` aux requests
- `services/course_planner.py` - Nouveau `_build_rag_section()`, prompts adapt√©s
- `main.py` - Fetch RAG context avant g√©n√©ration outline/cours
- `lib/course-types.ts` - Types TypeScript avec `document_ids`
- `hooks/useCourseGeneration.ts` - Envoi des document_ids dans les appels API

#### RAG 90% Coverage (Am√©lioration Janvier 2026)

**Objectif:** Garantir que 90%+ du contenu g√©n√©r√© provient des documents source.

**Param√®tres optimis√©s:**

| Param√®tre | Avant | Apr√®s | Impact |
|-----------|-------|-------|--------|
| `max_chunks` | 10-15 | **40** | +166% de contexte r√©cup√©r√© |
| `max_chars` | 24000 | **64000** | Documents longs support√©s |
| Instructions prompt | Soft | **Mandatory 90%** | Moins d'hallucinations |

**RAGVerifier - Service de v√©rification (nouveau):**

```
services/presentation-generator/services/rag_verifier.py
```

Analyse le contenu g√©n√©r√© vs les documents source:

| M√©thode | Poids | Description |
|---------|-------|-------------|
| **N-gram overlap** | 40% | D√©tecte les phrases copi√©es directement |
| **Term coverage** | 30% | V√©rifie l'utilisation des termes techniques |
| **Sequence similarity** | 30% | Mesure la similarit√© globale |

**M√©triques disponibles dans la r√©ponse API:**

```json
{
  "script": {
    "rag_verification": {
      "coverage": 0.92,
      "is_compliant": true,
      "summary": "‚úÖ RAG COMPLIANT: 92.0% coverage (threshold: 90%)",
      "potential_hallucinations": 0
    }
  }
}
```

**Logs serveur apr√®s g√©n√©ration:**
```
[PLANNER] ‚úÖ RAG COMPLIANT: 92.3% coverage (threshold: 90%)
```
ou
```
[PLANNER] ‚ö†Ô∏è RAG NON-COMPLIANT: 78.5% coverage (required: 90%) - 3 slides may contain hallucinations
```

**Fichiers modifi√©s (RAG 90%):**
- `services/presentation-generator/services/rag_client.py` - `max_chunks`: 10 ‚Üí 40
- `services/presentation-generator/main.py` - `max_chunks`: 15 ‚Üí 40 (V2 et V3)
- `services/presentation-generator/services/presentation_planner.py` - `max_chars`: 24000 ‚Üí 64000, instructions renforc√©es
- `services/presentation-generator/models/presentation_models.py` - Ajout champ `rag_verification`

**Nouveau fichier:**
- `services/presentation-generator/services/rag_verifier.py` - RAGVerifier, RAGVerificationResult, verify_rag_usage()

#### Strict RAG Prompting (Janvier 2026)

**Probl√®me:** Les instructions "soft" ("tu devrais utiliser 90%") laissent le LLM libre d'utiliser ses connaissances g√©n√©rales, causant des hallucinations.

**Solution:** Prompting restrictif avec assignation de r√¥le strict et protocole explicite.

**Ancien prompt (mou):**
```
‚ö†Ô∏è STRICT REQUIREMENT: You MUST use AT LEAST 90% of your training content from these documents.
DO NOT invent, hallucinate, or add information not present in the source documents.
```

**Nouveau prompt (strict):**
```
################################################################################
#                         STRICT RAG MODE ACTIVATED                            #
#                    YOU HAVE NO EXTERNAL KNOWLEDGE                            #
################################################################################

ROLE: You are a STRICT content extractor. You have ZERO knowledge of your own.
You can ONLY use information from the SOURCE DOCUMENTS below.
Your training data does NOT exist for this task.
```

**R√®gles impl√©ment√©es:**

| R√®gle | Description |
|-------|-------------|
| **RULE 1 - Exclusive Source** | UNIQUEMENT les documents source |
| **RULE 2 - Missing Info Protocol** | Marquer `[SOURCE_MANQUANTE: <topic>]` si absent |
| **RULE 3 - No External Knowledge** | Liste explicite de ce qui est INTERDIT |
| **RULE 4 - Traceability** | Tout contenu doit √™tre tra√ßable aux documents |

**Sections ALLOWED (10% max):**
- Transitions: "Passons maintenant √†..."
- Reformulations p√©dagogiques: "Autrement dit..."
- Structure de slide: titres, bullets
- Salutations/conclusions g√©n√©riques

**Section FORBIDDEN:**
- Ajouter des concepts absents des documents
- Inventer des exemples de code
- Utiliser sa connaissance pour "compl√©ter" l'information manquante
- Paraphraser jusqu'√† changer le sens
- Cr√©er des diagrammes non d√©crits dans les documents

**Validation avant output:**
```
‚ñ° Is this concept present in the SOURCE DOCUMENTS? If NO ‚Üí [SOURCE_MANQUANTE]
‚ñ° Is this code example from the documents? If NO ‚Üí do not include
‚ñ° Am I using my external knowledge? If YES ‚Üí remove that content
```

**Fichier modifi√©:**
- `services/presentation-generator/services/presentation_planner.py` - `_build_rag_section()` enti√®rement r√©√©crit

#### Cross-Encoder Re-ranking (Janvier 2026)

**Probl√®me:** La recherche vectorielle (cosine similarity) est "floue". Elle ram√®ne des documents qui parlent du m√™me sujet mais ne contiennent pas la r√©ponse exacte. Sans re-ranking, le LLM re√ßoit du bruit et compense avec ses propres connaissances.

**Solution:** Ajouter une √©tape de Cross-Encoder re-ranking apr√®s la recherche vectorielle.

**Nouveau pipeline RAG:**

```
Query utilisateur
      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 1: Vector Search (bi-encoder)  ‚îÇ
‚îÇ - Rapide (~20ms)                    ‚îÇ
‚îÇ - R√©cup√®re 30 candidats             ‚îÇ
‚îÇ - Cosine similarity (fuzzy)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 2: Cross-Encoder Re-ranking    ‚îÇ
‚îÇ - Pr√©cis (~50ms)                    ‚îÇ
‚îÇ - Query + Document ensemble         ‚îÇ
‚îÇ - Filtre le bruit s√©mantiquement    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 3: Return Top-K                ‚îÇ
‚îÇ - Chunks les plus pertinents        ‚îÇ
‚îÇ - Moins de bruit pour le LLM        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pourquoi Cross-Encoder > Bi-Encoder:**

| Aspect | Bi-Encoder (Vector) | Cross-Encoder (Re-rank) |
|--------|---------------------|-------------------------|
| **Input** | Query et Doc s√©par√©s | Query + Doc ensemble |
| **Vitesse** | ~20ms pour 1000 docs | ~50ms pour 30 docs |
| **Pr√©cision** | Similarit√© topique | Pertinence exacte |
| **Usage** | Retrieval (recall) | Re-ranking (precision) |

**Exemple concret:**

```
Query: "Quelles sont les mesures de s√©curit√© de Kafka?"

AVANT (sans re-ranking):
1. "Kafka est un syst√®me de messaging..." (0.82) ‚Üê Hors sujet
2. "L'architecture de Kafka comprend..." (0.80) ‚Üê Hors sujet
3. "L'authentification SASL dans Kafka..." (0.78) ‚Üê R√©pond!

APR√àS (avec re-ranking):
1. "L'authentification SASL dans Kafka..." (0.91) ‚Üê R√©pond!
2. "Le chiffrement TLS pour Kafka..." (0.87) ‚Üê R√©pond!
3. "Kafka est un syst√®me de messaging..." (0.32) ‚Üê Filtr√©
```

**Configuration:** `RERANKER_BACKEND=auto|cross-encoder|cross-encoder-accurate|tfidf`

| Backend | Mod√®le | Latence | Qualit√© |
|---------|--------|---------|---------|
| `auto` | MiniLM ‚Üí TF-IDF fallback | ~50ms | ‚≠ê‚≠ê‚≠ê |
| `cross-encoder` | ms-marco-MiniLM-L-6-v2 | ~50ms | ‚≠ê‚≠ê‚≠ê |
| `cross-encoder-accurate` | ms-marco-MiniLM-L-12-v2 | ~100ms | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `tfidf` | TF-IDF keywords | ~5ms | ‚≠ê‚≠ê |

**Fichiers cr√©√©s/modifi√©s:**

- `services/course-generator/services/reranker.py` - **NOUVEAU** - CrossEncoderReranker, TFIDFReranker, RerankerFactory
- `services/course-generator/services/retrieval_service.py` - Int√©gration reranker dans `query()` et `_rerank_results()`
- `services/course-generator/models/document_models.py` - Ajout `rerank_score` √† RAGChunkResult

**Logs serveur:**
```
[RAG] Vector search returned 30 candidates
[RAG] Re-ranking 30 results with CrossEncoder...
[RAG] Re-ranking complete. Top score: 0.912 -> 0.234
[RAG] Returning 15 re-ranked chunks
```

#### RAG Threshold Validation (Janvier 2026)

**Probl√®me:** Quand le RAG ne retourne rien ou peu de contenu, le graphe continue la g√©n√©ration standard. Le LLM compense avec ses propres connaissances, causant des hallucinations.

**Solution:** Ajouter une branche conditionnelle bas√©e sur le nombre de tokens RAG.

**Nouveau flux conditionnel:**

```
                    pedagogical_analysis
                           ‚Üì
                  check_rag_threshold
                    /            \
          (blocked)/              \(ok)
                  ‚Üì                ‚Üì
         insufficient_rag     plan_course
                  ‚Üì                ‚Üì
                END           g√©n√©ration...
```

**Seuils configurables:**

| Tokens RAG | Mode | Action |
|------------|------|--------|
| < 500 | `BLOCKED` | **Arr√™t** - Erreur retourn√©e, demande plus de documents |
| 500-2000 | `PARTIAL` | **Warning** - G√©n√©ration continue avec avertissement |
| > 2000 | `FULL` | **OK** - Mode RAG optimal, 90%+ couverture attendue |
| 0 (pas de docs) | `NONE` | **Standard** - G√©n√©ration IA pure avec warning |

**Configuration:** Variables d'environnement

```bash
RAG_MINIMUM_TOKENS=500   # Seuil de blocage (hard)
RAG_QUALITY_TOKENS=2000  # Seuil de qualit√© (warning)
```

**R√©ponse API enrichie:**

```json
{
  "script": {
    "rag_verification": {
      "mode": "partial",
      "token_count": 1200,
      "coverage": 0.85,
      "is_compliant": false,
      "warning": "Limited source content: 1200 tokens (recommended: 2000+)"
    }
  }
}
```

**Messages d'erreur (mode BLOCKED):**

```
Cannot generate content for 'Apache Kafka Security': Insufficient source
content: 320 tokens retrieved (minimum required: 500). Please provide more
comprehensive documents or check that the documents cover the requested topic.
```

**Suggestions retourn√©es √† l'utilisateur:**

- Upload more documents covering the topic
- Ensure documents contain text (not just images)
- Check that documents are relevant to the requested topic
- Consider using PDFs or Word documents with more content

**Fichiers cr√©√©s:**

- `services/course-generator/services/rag_threshold_validator.py`
- `services/presentation-generator/services/rag_threshold_validator.py`

**Fichiers modifi√©s:**

- `agents/course_graph.py` - Nouveau node `check_rag_threshold` + `handle_insufficient_rag` + routing conditionnel
- `services/presentation_planner.py` - V√©rification threshold avant `generate_script()`

**Logs serveur:**

```
[RAG_CHECK] FULL mode: 4500 tokens (sufficient)
```
ou
```
[RAG_CHECK] BLOCKED: 320 tokens (insufficient)
[INSUFFICIENT_RAG] Generation blocked. Tokens: 320
[INSUFFICIENT_RAG] User should provide more comprehensive documents.
```

---

## Phase 3 - Impl√©mentation (COMPL√âT√âE)

### Backend (media-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/video_editor_models.py` - Mod√®les Pydantic complets
  - SegmentType, TransitionType, SegmentStatus, ProjectStatus (Enums)
  - AudioTrack: piste audio avec volume, fade in/out
  - VideoSegment: segment timeline avec trim, transitions, opacit√©
  - TextOverlay, ImageOverlay: overlays configurables
  - VideoProject: projet complet avec segments et settings
  - Request/Response models pour l'API
- `services/timeline_service.py` - Gestion timeline
  - ProjectRepository: stockage in-memory (PostgreSQL en prod)
  - TimelineService: CRUD projets, segments, overlays
  - _recalculate_timeline: mise √† jour automatique des temps
- `services/segment_manager.py` - Gestion des m√©dias
  - process_upload: traitement vid√©o/audio/image
  - _get_video_duration, _generate_thumbnail via ffprobe/ffmpeg
  - trim_video, extract_audio: utilitaires FFmpeg
  - Validation formats et tailles
- `services/video_merge_service.py` - Rendu final FFmpeg
  - render_project: orchestration du rendu complet
  - _prepare_segment: normalisation r√©solution/fps
  - _image_to_video: conversion slides en vid√©o
  - _concatenate_segments: fusion avec transitions
  - _finalize_video: overlays, musique, encodage final
  - QUALITY_PRESETS: low/medium/high

**Fichiers modifi√©s:**
- `main.py` - +400 lignes pour les endpoints Video Editor API

### Frontend (editor)

**Nouveaux fichiers cr√©√©s:**
- `lib/editor-types.ts` - Types TypeScript
  - Enums: SegmentType, TransitionType, SegmentStatus, ProjectStatus
  - Interfaces: VideoSegment, VideoProject, TextOverlay, ImageOverlay
  - Request/Response types pour l'API
  - Helper functions: formatDuration, getSegmentTypeLabel, etc.
- `hooks/useVideoEditor.ts` - Hook React complet
  - State: project, isLoading, isSaving, isRendering, renderJob
  - Project actions: create, load, update, delete
  - Segment actions: add, upload, update, remove, reorder, split
  - Overlay actions: addTextOverlay, addImageOverlay
  - Render actions: startRender, checkRenderStatus, createPreview
- `components/SegmentItem.tsx` - Composant segment
  - Affichage thumbnail, dur√©e, type
  - Toggle mute audio
  - Drag & drop pour r√©ordonnancement
  - Menu contextuel (edit, mute, remove)
  - Handles de trim visuels
- `components/Timeline.tsx` - Timeline principale
  - R√®gle temporelle avec markers
  - Playhead interactif
  - Drop zones pour r√©ordonnancement
  - Zoom in/out
  - Drag & drop upload
- `components/SegmentProperties.tsx` - Panel propri√©t√©s
  - Trim start/end
  - Volume audio + mute toggle
  - Opacit√©
  - Transitions in/out avec dur√©e
  - Split segment
- `page.tsx` - Page √©diteur compl√®te
  - Modal cr√©ation projet
  - Preview vid√©o
  - Contr√¥les playback (play/pause/stop)
  - Upload m√©dia
  - Export/render avec progression
  - Gestion erreurs

### Acc√®s √† l'√©diteur
- URL: `/dashboard/studio/editor`
- Param√®tres: `?projectId=xxx` ou `?courseJobId=xxx` pour import

---

## Phase 4 - Impl√©mentation (COMPL√âT√âE)

### Backend (media-generator)

**Nouveaux fichiers cr√©√©s:**
- `models/voice_cloning_models.py` - Mod√®les Pydantic complets
  - VoiceProvider, SampleStatus, VoiceProfileStatus (Enums)
  - VoiceSample: √©chantillon audio avec quality metrics
  - VoiceProfile: profil vocal complet avec consent tracking
  - VoiceGenerationSettings: param√®tres de g√©n√©ration
  - Request/Response models pour l'API
- `services/voice_sample_service.py` - Gestion √©chantillons
  - process_sample: upload et validation audio
  - _get_audio_duration via ffprobe
  - _analyze_quality: score qualit√©, bruit, clart√©
  - convert_to_standard_format: normalisation audio
  - VoiceSampleRequirements: specs pour uploads
- `services/voice_cloning_service.py` - Int√©gration ElevenLabs
  - create_cloned_voice: cr√©ation voix via API
  - generate_speech: g√©n√©ration TTS
  - delete_voice: suppression voix
  - get_usage_stats: stats utilisation API
- `services/voice_profile_manager.py` - Orchestration workflow
  - VoiceProfileRepository: stockage in-memory
  - create_profile, get_profile, list_profiles, delete_profile
  - add_sample, remove_sample
  - start_training avec v√©rification consentement
  - generate_speech, preview_voice
  - get_training_requirements

**Fichiers modifi√©s:**
- `main.py` - +250 lignes pour les endpoints Voice Cloning API

### Frontend (voice-clone)

**Nouveaux fichiers cr√©√©s:**
- `lib/voice-types.ts` - Types TypeScript
  - Enums: VoiceProvider, SampleStatus, VoiceProfileStatus
  - Interfaces: VoiceSample, VoiceProfile, VoiceGenerationSettings
  - Request/Response types
  - Helper functions: formatDuration, getStatusLabel, etc.
- `hooks/useVoiceClone.ts` - Hook React complet
  - State: profiles, selectedProfile, requirements
  - Profile actions: create, select, update, delete
  - Sample actions: upload, delete
  - Training actions: startTraining, checkTrainingStatus
  - Generation actions: generateSpeech, previewVoice
- `components/VoiceSampleUpload.tsx` - Upload √©chantillons
  - Drag & drop avec validation format
  - Progress bar dur√©e totale
  - Liste des samples avec quality score
  - Tips d'enregistrement
- `page.tsx` - Page gestion des voix
  - Liste des profils vocaux
  - Cr√©ation profil (nom, genre, accent)
  - Upload samples avec progress
  - Modal consentement pour training
  - Test voice avec audio player
  - Stats utilisation

### Acc√®s au Voice Cloning
- URL: `/dashboard/studio/voice-clone`

### Variables d'environnement
```
ELEVENLABS_API_KEY=your_api_key_here
```

---

## Conventions de code

### Backend (Python/FastAPI)
- Async/await pour toutes les op√©rations I/O
- Pydantic pour la validation des donn√©es
- Timeout de 120s pour les appels OpenAI
- Logging avec `print(..., flush=True)` pour Docker

### Frontend (Next.js/React)
- `useCallback` pour les handlers pass√©s en props
- `useRef` pour les callbacks dans useEffect
- Composants client marqu√©s `'use client'`

---

## Fichiers cl√©s

### Course Generator
- `services/course-generator/services/course_planner.py` - G√©n√©ration du curriculum
- `services/course-generator/services/context_questions.py` - Questions contextuelles
- `services/course-generator/models/course_models.py` - Mod√®les de donn√©es

### Frontend Courses
- `frontend/src/app/dashboard/studio/courses/page.tsx` - Page principale
- `frontend/src/app/dashboard/studio/courses/lib/course-types.ts` - Types TypeScript
- `frontend/src/app/dashboard/studio/courses/components/` - Composants UI

---

## Phase 5 - Impl√©mentation (COMPL√âT√âE)

### Migration pgvector

**Fichiers modifi√©s:**
- `docker-compose.yml` - Image `pgvector/pgvector:pg16`, variable `VECTOR_BACKEND=pgvector`
- `infrastructure/docker/init-pgvector.sql` - Script cr√©ation table + index HNSW
- `services/course-generator/services/vector_store.py` - Classe `PgVectorStore` avec asyncpg
- `services/course-generator/requirements.txt` - D√©pendances asyncpg, pgvector

### Phase 5A: Analytics & Metrics

**Nouveaux fichiers cr√©√©s:**
- `models/analytics_models.py` - Mod√®les Pydantic (CourseMetrics, APIUsageMetrics, etc.)
- `services/analytics_service.py` - Service tracking et agr√©gation

**Endpoints API Analytics:**
- `GET /api/v1/analytics/dashboard` - Dashboard complet
- `GET /api/v1/analytics/user/{user_id}` - R√©sum√© utilisateur
- `GET /api/v1/analytics/api-usage` - Rapport usage API
- `GET /api/v1/analytics/quota/{user_id}` - Quotas utilisateur
- `POST /api/v1/analytics/track` - Track √©v√©nement

**Frontend:**
- `frontend/src/app/dashboard/studio/analytics/` - Dashboard analytics cours

### Phase 5B: Multi-langue (10 langues)

**Langues support√©es:** EN, FR, ES, DE, PT, IT, NL, PL, RU, ZH

**Nouveaux fichiers cr√©√©s:**
- `models/translation_models.py` - Mod√®les (SupportedLanguage, CourseTranslation)
- `services/translation_service.py` - Service traduction via GPT-4o-mini

**Endpoints API Translation:**
- `GET /api/v1/translation/languages` - Langues support√©es
- `POST /api/v1/translation/translate` - Traduire un texte
- `POST /api/v1/translation/translate-batch` - Traduction batch
- `POST /api/v1/translation/detect` - D√©tection de langue
- `POST /api/v1/translation/course/{course_id}` - Traduire un cours complet

### Phase 5C: Mon√©tisation (Stripe + PayPal)

**Plans disponibles:**
| Plan | Prix/mois | Cours/mois | Storage | API Budget |
|------|-----------|------------|---------|------------|
| Free | $0 | 3 | 1 GB | $5 |
| Starter | $19 | 10 | 10 GB | $25 |
| Pro | $49 | 50 | 50 GB | $100 |
| Enterprise | $199 | Illimit√© | 500 GB | $500 |

**Nouveaux fichiers cr√©√©s:**
- `models/billing_models.py` - Mod√®les (Subscription, Payment, Invoice)
- `services/billing_service.py` - Int√©gration Stripe + PayPal

**Endpoints API Billing:**
- `GET /api/v1/billing/plans` - Liste des plans
- `POST /api/v1/billing/checkout` - Cr√©er session checkout
- `GET /api/v1/billing/subscription/{user_id}` - Abonnement actuel
- `POST /api/v1/billing/cancel` - Annuler abonnement
- `POST /api/v1/billing/portal` - Portail de facturation
- `POST /api/v1/billing/webhooks/stripe` - Webhook Stripe
- `POST /api/v1/billing/webhooks/paypal` - Webhook PayPal

**Variables d'environnement:**
```
STRIPE_SECRET_KEY=sk_...
STRIPE_WEBHOOK_SECRET=whsec_...
PAYPAL_CLIENT_ID=...
PAYPAL_CLIENT_SECRET=...
```

### Phase 5D: Collaboration (√âquipes)

**R√¥les disponibles:**
| R√¥le | Permissions |
|------|-------------|
| Owner | Tout (g√©rer √©quipe, billing, supprimer workspace) |
| Admin | G√©rer membres, cr√©er/√©diter/supprimer cours |
| Editor | Cr√©er cours, √©diter ses propres cours |
| Viewer | Voir cours seulement |

**Nouveaux fichiers cr√©√©s:**
- `models/collaboration_models.py` - Mod√®les (Workspace, TeamMember, CourseShare)
- `services/collaboration_service.py` - Service gestion √©quipes

**Endpoints API Collaboration:**
- `POST /api/v1/workspaces` - Cr√©er workspace
- `GET /api/v1/workspaces` - Lister workspaces
- `GET /api/v1/workspaces/{id}` - D√©tails workspace
- `PATCH /api/v1/workspaces/{id}` - Modifier workspace
- `POST /api/v1/workspaces/{id}/invite` - Inviter membre
- `POST /api/v1/workspaces/accept-invitation` - Accepter invitation
- `DELETE /api/v1/workspaces/{id}/members/{member_id}` - Retirer membre
- `PATCH /api/v1/workspaces/{id}/members/{id}/role` - Changer r√¥le
- `POST /api/v1/workspaces/{id}/leave` - Quitter workspace
- `POST /api/v1/courses/{id}/share` - Partager cours
- `GET /api/v1/courses/{id}/shares` - Liste partages
- `GET /api/v1/workspaces/{id}/activity` - Journal d'activit√©

---

## Phase 6 - Enhanced Code & Diagram Generation (IMPL√âMENT√âE)

### Objectifs
Am√©liorer la qualit√© du code et des diagrammes g√©n√©r√©s pour atteindre un niveau professionnel/enterprise-grade.

### Am√©liorations apport√©es

#### 1. TechPromptBuilder - Prompts contextuels dynamiques
Le nouveau `TechPromptBuilder` g√©n√®re des prompts adapt√©s selon:
- **Niveau de l'audience**: D√©butant absolu ‚Üí Expert
- **Domaine tech**: Data Engineering, DevOps, ML, Cybersecurity, etc.
- **Carri√®re cible**: 545+ m√©tiers IT avec contexte sp√©cifique
- **Langages**: 120+ langages avec exemples de style

#### 2. Standards de qualit√© code obligatoires
Tous les codes g√©n√©r√©s respectent:
- Conventions de nommage (descriptif, pas de single letters)
- Structure (max 20 lignes/fonction, max 3 niveaux de nesting)
- Testabilit√© (fonctions pures, DI, pas d'√©tat global)
- Documentation (docstrings, type hints)
- Gestion d'erreurs (exceptions sp√©cifiques, messages significatifs)
- Design patterns appropri√©s

#### 3. DiagramsRenderer - Diagrammes professionnels
Int√©gr√© dans `diagram_generator.py` comme m√©thode **PRIMARY**:
- **Ic√¥nes officielles** AWS, Azure, GCP, Kubernetes, On-Premise
- **Rendu PNG** haute qualit√© avec post-traitement
- **Clustering** logique des composants
- **G√©n√©ration via GPT-4o** pour meilleure pr√©cision
- **D√©tection auto** du cloud provider depuis la description

**Ordre de priorit√© des renderers:**
1. **PRIMARY** - Python Diagrams (architecture, hierarchy, process)
2. **SECONDARY** - Mermaid via Kroki (flowcharts, sequences, mindmaps)
3. **TERTIARY** - PIL fallback

#### 4. Mod√®les de donn√©es exhaustifs

**tech_domains.py** contient:
```python
class CodeLanguage(str, Enum):
    # 120+ langages incluant:
    PYTHON, JAVASCRIPT, GO, RUST, SOLIDITY, QISKIT, CIRQ...

class TechDomain(str, Enum):
    # 80+ domaines incluant:
    DATA_ENGINEERING, MLOPS, DEVOPS, KUBERNETES, QUANTUM_COMPUTING...

class TechCareer(str, Enum):
    # 545+ m√©tiers IT 360¬∞ incluant:
    DATA_LINEAGE_DEVELOPER, MLOPS_ENGINEER, PLATFORM_ENGINEER...
```

#### 5. Visual-Generator Microservice (Architecture)

Le service `visual-generator` est un microservice isol√© qui g√®re la g√©n√©ration de diagrammes:

**Communication:**
```
presentation-generator ‚Üí HTTP POST ‚Üí visual-generator:8003/api/v1/diagrams/generate
```

**Endpoints:**
- `POST /api/v1/diagrams/generate` - G√©n√©ration diagramme depuis description
- `POST /api/v1/diagrams/mermaid` - Rendu Mermaid
- `POST /api/v1/diagrams/detect` - D√©tection besoin diagramme
- `GET /api/v1/diagrams/{filename}` - R√©cup√©ration image
- `DELETE /api/v1/diagrams/{filename}` - Suppression
- `POST /api/v1/diagrams/cleanup` - Nettoyage fichiers anciens

#### 6. Complexit√© des diagrammes par audience

Le syst√®me adapte automatiquement la complexit√© des diagrammes selon l'audience cible:

| Audience | Nodes Max | Caract√©ristiques |
|----------|-----------|------------------|
| **BEGINNER** | 5-7 | Concepts haut-niveau, pas de d√©tails r√©seau, labels courts |
| **SENIOR** | 10-15 | VPCs, caching, load balancers, redundancy, Edge labels |
| **EXECUTIVE** | 6-8 | Flux de valeur, termes business, pas de jargon technique |

**Flux complet de propagation de l'audience:**
```
PresentationPlanner (GPT-4 avec instructions DIAGRAM COMPLEXITY BY AUDIENCE)
    ‚Üì target_audience dans PresentationScript
PresentationCompositor / LangGraphOrchestrator
    ‚Üì target_audience pass√© √† SlideGenerator
SlideGenerator.generate_slide_image(slide, style, target_audience)
    ‚Üì target_audience pass√© √† _render_diagram_slide
DiagramGeneratorService.generate_diagram(..., target_audience)
    ‚Üì Mapping string ‚Üí TargetAudience enum
DiagramsRenderer.generate_and_render(audience=TargetAudience.SENIOR)
    ‚Üì HTTP POST avec audience + cheat_sheet
visual-generator:8003/api/v1/diagrams/generate
    ‚Üì Prompt GPT-4o avec AUDIENCE_INSTRUCTIONS + DIAGRAMS_CHEAT_SHEET
G√©n√©ration code Python Diagrams ‚Üí Ex√©cution Graphviz ‚Üí PNG
```

**DIAGRAMS_CHEAT_SHEET:**
Liste exhaustive des imports valides pour emp√™cher les hallucinations du LLM:
- √âvite les imports inexistants (ex: `from diagrams.aws.compute import NonExistentService`)
- Couvre: AWS, Azure, GCP, Kubernetes, On-Premise, Programming, SaaS, Generic

### Architecture

```
services/presentation-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ tech_domains.py           # Enums: CodeLanguage, TechDomain, TechCareer
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ tech_prompt_builder.py    # Construction prompts contextuels
    ‚îú‚îÄ‚îÄ presentation_planner.py   # Int√©gration du prompt builder + DIAGRAM COMPLEXITY
    ‚îú‚îÄ‚îÄ slide_generator.py        # Param√®tre target_audience ajout√©
    ‚îú‚îÄ‚îÄ diagram_generator.py      # Client HTTP vers visual-generator + audience mapping
    ‚îú‚îÄ‚îÄ presentation_compositor.py # Passage target_audience depuis script
    ‚îú‚îÄ‚îÄ langgraph_orchestrator.py # Passage target_audience depuis script
    ‚îî‚îÄ‚îÄ agents/
        ‚îî‚îÄ‚îÄ visual_sync_agent.py  # Propagation target_audience

services/visual-generator/         # MICROSERVICE ISOL√â (Port 8003)
‚îú‚îÄ‚îÄ main.py                       # FastAPI avec endpoints diagrammes
‚îú‚îÄ‚îÄ Dockerfile                    # Graphviz + d√©pendances lourdes
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ visual_models.py          # DiagramType, DiagramStyle, RenderFormat
‚îî‚îÄ‚îÄ renderers/
    ‚îú‚îÄ‚îÄ diagrams_renderer.py      # Python Diagrams + GPT-4o + audience/cheat_sheet
    ‚îú‚îÄ‚îÄ mermaid_renderer.py       # Mermaid via Kroki (PRIMARY) + mermaid.ink (FALLBACK)
    ‚îî‚îÄ‚îÄ matplotlib_renderer.py    # Charts de donn√©es

#### 7. Kroki Self-Hosted (Diagram Rendering)

Le rendu Mermaid utilise **Kroki self-hosted** comme renderer PRIMARY avec fallback vers mermaid.ink:

**Avantages Kroki:**
- Self-hosted = pas de d√©pendance externe en production
- Privacy: les diagrammes restent dans l'infrastructure
- Supporte 20+ types de diagrammes (Mermaid, PlantUML, D2, GraphViz, etc.)
- Fiabilit√©: pas de rate limiting externe

**Ordre de priorit√©:**
1. **PRIMARY**: Kroki self-hosted (`http://kroki:8000`)
2. **FALLBACK**: mermaid.ink public API (si Kroki indisponible)

**Configuration:**
```python
# mermaid_renderer.py
KROKI_URL = os.getenv("KROKI_URL", "http://kroki:8000")
USE_KROKI = os.getenv("USE_KROKI", "true").lower() == "true"
```

**Docker Compose:**
```yaml
kroki:
  image: yuzutech/kroki
  container_name: viralify-kroki
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
```

#### 8. S√©curit√© - Validation AST du code g√©n√©r√©

Le `DiagramsRenderer` ex√©cute du code Python g√©n√©r√© par GPT-4o. Pour pr√©venir les attaques par injection de code, un validateur AST (`CodeSecurityValidator`) analyse le code AVANT ex√©cution:

**Protections impl√©ment√©es:**

| Type | √âl√©ments bloqu√©s |
|------|------------------|
| **Imports dangereux** | `os`, `subprocess`, `sys`, `socket`, `requests`, `pickle`, etc. |
| **Fonctions dangereuses** | `exec()`, `eval()`, `open()`, `__import__()`, `getattr()` |
| **Attributs dunder** | `__class__`, `__bases__`, `__subclasses__`, `__globals__` |
| **Imports autoris√©s** | UNIQUEMENT `diagrams.*` |

**Flux de validation:**
```
Code g√©n√©r√© par GPT-4o
    ‚Üì
CodeSecurityValidator.validate(code)
    ‚Üì AST parsing
    ‚Üì Import whitelist check
    ‚Üì Blocked functions check
    ‚Üì Dangerous attributes check
    ‚Üì
is_safe = True ‚Üí Ex√©cution autoris√©e
is_safe = False ‚Üí REJET + log s√©curit√©
```

**Exemple d'attaque bloqu√©e:**
```python
# GPT pourrait g√©n√©rer (accidentellement ou par prompt injection):
import os
os.system("rm -rf /")  # ‚ùå BLOQU√â: "SECURITY: Blocked import 'os'"

# ou
exec("malicious_code")  # ‚ùå BLOQU√â: "SECURITY: Blocked function 'exec()'"
```

### Fichiers cr√©√©s/modifi√©s

**Nouveaux fichiers:**
- `models/tech_domains.py` - 545+ m√©tiers, 80+ domaines, 120+ langages
- `services/tech_prompt_builder.py` - Construction de prompts dynamiques
- `services/visual-generator/main.py` - Microservice FastAPI
- `services/visual-generator/Dockerfile` - Image avec Graphviz

**Fichiers modifi√©s (Phase 6 + audience + career):**
- `services/diagram_generator.py` - Client HTTP + DIAGRAMS_CHEAT_SHEET + audience mapping + **career focus**
- `services/presentation_planner.py` - DIAGRAM COMPLEXITY BY AUDIENCE instructions
- `services/slide_generator.py` - Param√®tres `target_audience` + `target_career`
- `services/presentation_compositor.py` - Passage `target_audience` + `target_career`
- `services/langgraph_orchestrator.py` - Passage `target_audience` + `target_career`
- `services/agents/visual_sync_agent.py` - Propagation `target_audience` + `target_career`
- `renderers/diagrams_renderer.py` - Audience instructions + cheat_sheet + **CodeSecurityValidator** (AST validation)
- `models/presentation_models.py` - Champ `target_career` ajout√© √† `PresentationScript` et `GeneratePresentationRequest`
- `models/tech_domains.py` - `DiagramFocus` enum, `CAREER_DIAGRAM_FOCUS_MAP`, `DIAGRAM_FOCUS_INSTRUCTIONS`
- `renderers/mermaid_renderer.py` - Kroki self-hosted (PRIMARY) + mermaid.ink (FALLBACK)
- `docker-compose.prod.yml` - Services visual-generator + kroki ajout√©s
- `docker-compose.yml` - Service kroki ajout√©

#### 9. DiagramFocus - Diff√©renciation par carri√®re

Le syst√®me adapte la **perspective** des diagrammes selon la carri√®re cible (545+ m√©tiers):

**Principe:**
- Un Data Engineer et un Cloud Architect regardent le m√™me syst√®me diff√©remment
- Le Data Engineer veut voir pipelines, ETL, data lakes
- L'Architect veut voir VPCs, load balancers, zones de disponibilit√©

**DiagramFocus Enum:**

| Focus | Exemple de carri√®res | Ce qui est montr√© |
|-------|---------------------|-------------------|
| **CODE** | Software Developer, Backend Engineer | APIs, services, microservices, queues |
| **INFRASTRUCTURE** | Cloud Architect, Platform Engineer | VPCs, load balancers, scaling, HA |
| **DATA** | Data Engineer, Analytics Engineer | Pipelines, ETL/ELT, warehouses, lakes |
| **ML_PIPELINE** | ML Engineer, MLOps Engineer | Feature stores, model serving, training |
| **SECURITY** | Security Engineer, CISO | Zones, firewalls, IAM, encryption |
| **NETWORK** | Network Engineer, SRE | Topology, routing, DNS, CDN |
| **DATABASE** | DBA, Database Architect | Replication, sharding, HA, backups |
| **BUSINESS** | CTO, VP Engineering | Value flow, ROI, high-level view |
| **QA_TESTING** | QA Engineer, Test Lead | Test pyramid, CI/CD, environments |
| **EMBEDDED** | Firmware Engineer, IoT Developer | Hardware, sensors, protocols |

**API Usage:**
```python
# GeneratePresentationRequest
{
    "topic": "Building a data pipeline with Apache Kafka",
    "target_audience": "senior developers",
    "target_career": "data_engineer"  # NEW: diff√©rencie les diagrammes
}
```

**Flux de propagation:**
```
GeneratePresentationRequest.target_career
    ‚Üì Stock√© dans PresentationScript.target_career
PresentationCompositor / LangGraphOrchestrator
    ‚Üì target_career pass√© √† SlideGenerator
SlideGenerator.generate_slide_image(slide, style, target_audience, target_career)
    ‚Üì target_career pass√© √† _render_diagram_slide
DiagramGeneratorService.generate_diagram(..., target_career)
    ‚Üì Parsing TechCareer enum + get_diagram_instructions_for_career()
DiagramsRenderer._build_enhanced_description(career=TechCareer.DATA_ENGINEER)
    ‚Üì Instructions sp√©cifiques ajout√©es au prompt GPT-4o
```

### D√©pendances

```
# visual-generator/requirements.txt
diagrams>=0.23.4
fastapi
uvicorn
openai
pillow

# System requirement (dans Dockerfile visual-generator)
# Graphviz doit √™tre install√©:
# Ubuntu: apt-get install graphviz graphviz-dev
# macOS: brew install graphviz
# Windows: choco install graphviz
```

### Variables d'environnement

```
# presentation-generator
VISUAL_GENERATOR_URL=http://visual-generator:8003

# visual-generator
OPENAI_API_KEY=sk-...
OUTPUT_DIR=/tmp/viralify/diagrams
KROKI_URL=http://kroki:8000
USE_KROKI=true
```

---

## Phase 7 - Source Traceability System (IMPL√âMENT√âE)

### Objectifs
Syst√®me complet de tra√ßabilit√© des sources utilis√©es pour la g√©n√©ration de cours, permettant de savoir exactement d'o√π vient chaque information.

### Phase 7.1: PedagogicalRole & Traceability

#### PedagogicalRole Enum
Chaque source upload√©e peut avoir un r√¥le p√©dagogique:

| R√¥le | Icon | Description |
|------|------|-------------|
| **THEORY** | üìö | D√©finitions, concepts, explications th√©oriques |
| **EXAMPLE** | üí° | Exemples pratiques, d√©mos, tutoriels |
| **REFERENCE** | üìñ | Documentation officielle, sp√©cifications |
| **OPINION** | üí≠ | Notes personnelles, perspectives |
| **DATA** | üìä | Statistiques, √©tudes, recherche |
| **CONTEXT** | üîç | Informations de fond, historique, pr√©requis |
| **AUTO** | ü§ñ | L'IA d√©termine automatiquement le r√¥le |

#### Citation Configuration
```python
class SourceCitationConfig:
    enable_vocal_citations: bool = False  # Citations vocales dans le voiceover
    citation_style: CitationStyle = NATURAL  # NATURAL, ACADEMIC, MINIMAL, NONE
    show_traceability_panel: bool = True   # Panel de tra√ßabilit√© visible
    include_page_numbers: bool = True
    include_timestamps: bool = True
    include_quote_excerpts: bool = True
```

#### Endpoints API Traceability
- `GET /api/v1/traceability/citation-styles` - Styles de citation disponibles
- `GET /api/v1/traceability/pedagogical-roles` - R√¥les p√©dagogiques
- `GET /api/v1/traceability/default-config` - Configuration par d√©faut
- `GET /api/v1/courses/{job_id}/traceability` - Tra√ßabilit√© compl√®te d'un cours
- `GET /api/v1/courses/{job_id}/lectures/{lecture_id}/traceability` - Tra√ßabilit√© d'une lecture
- `PATCH /api/v1/sources/{source_id}/pedagogical-role` - Modifier le r√¥le d'une source

### Phase 7.2: Coherence Check

Validation de la coh√©rence p√©dagogique entre les lectures.

#### Fonctionnalit√©s
- **D√©tection des pr√©requis manquants**: Si une lecture utilise un concept introduit plus tard
- **D√©tection des gaps conceptuels**: Trop de nouveaux pr√©requis d'un coup
- **Score de coh√©rence**: 0-100, avec seuil de 50 pour warning
- **Enrichissement**: Ajoute `key_concepts`, `prerequisites`, `introduces`, `prepares_for` √† chaque lecture

#### Int√©gration Pipeline
```
run_planning ‚Üí check_coherence ‚Üí build_knowledge_graph ‚Üí iterate_lectures
```

#### Fichiers
- `services/coherence_service.py` - CoherenceCheckService
- `models/course_models.py` - Champs Lecture enrichis

### Phase 7.3: Knowledge Graph & Cross-Reference

Construction d'un graphe de connaissances et analyse des r√©f√©rences crois√©es.

#### Knowledge Graph
Extraction de concepts depuis les sources avec relations:

```python
@dataclass
class Concept:
    name: str
    canonical_name: str
    aliases: List[str]
    definitions: List[ConceptDefinition]  # Une d√©finition par source
    consolidated_definition: str  # Synth√®se de toutes les sources
    prerequisites: List[str]      # Concepts pr√©requis
    related_concepts: List[str]
    parent_concepts: List[str]    # Concepts plus larges
    child_concepts: List[str]     # Concepts plus sp√©cifiques
    complexity_level: int         # 1-5
    frequency: int                # Nombre de mentions
```

#### Cross-Reference Analysis
Analyse comment les sources se compl√®tent:

```python
@dataclass
class TopicCrossReference:
    topic: str
    source_contributions: List[SourceContribution]
    consolidated_definition: str
    consolidated_examples: List[str]
    points_of_agreement: List[str]
    points_of_disagreement: List[str]
    coverage_score: float  # 0-1
    missing_aspects: List[str]  # theory, examples, reference, data
```

#### Endpoints API Knowledge Graph
- `GET /api/v1/courses/{job_id}/knowledge-graph` - Graphe de connaissances complet
- `GET /api/v1/courses/{job_id}/knowledge-graph/concepts` - Liste des concepts (pagin√©)
- `GET /api/v1/courses/{job_id}/knowledge-graph/concept/{concept_id}` - D√©tails d'un concept
- `GET /api/v1/courses/{job_id}/cross-references` - Analyse des r√©f√©rences crois√©es
- `GET /api/v1/courses/{job_id}/cross-references/topic/{topic_name}` - Cross-ref pour un topic
- `POST /api/v1/sources/analyze-cross-references` - Analyser sources ind√©pendamment d'un cours

### Architecture

```
services/course-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ traceability_models.py    # SourceCitationConfig, ContentReference, etc.
‚îÇ   ‚îî‚îÄ‚îÄ course_models.py          # Champs traceability, knowledge_graph ajout√©s
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ traceability_service.py   # G√©n√©ration de citations, r√©f√©rences
‚îÇ   ‚îú‚îÄ‚îÄ coherence_service.py      # Validation coh√©rence p√©dagogique
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_graph.py        # KnowledgeGraphBuilder
‚îÇ   ‚îú‚îÄ‚îÄ cross_reference_service.py # CrossReferenceService
‚îÇ   ‚îî‚îÄ‚îÄ source_library.py         # Organisation par PedagogicalRole
‚îî‚îÄ‚îÄ agents/
    ‚îú‚îÄ‚îÄ orchestrator_graph.py     # Nodes: check_coherence, build_knowledge_graph
    ‚îî‚îÄ‚îÄ state.py                  # Champs coherence + knowledge_graph
```

### Pipeline Complet

```
validate_input
    ‚Üì
run_planning (curriculum)
    ‚Üì
check_coherence (Phase 7.2)
    ‚Üì Validate prerequisites, detect concept gaps, enrich lectures
build_knowledge_graph (Phase 7.3)
    ‚Üì Extract concepts, build relationships, analyze cross-references
iterate_lectures (production)
    ‚Üì
package_output
    ‚Üì
finalize
```

### Commits

- `84039db` - feat(traceability): implement Phase 1 - Source Traceability System
- `769cdf1` - feat(coherence): implement Phase 2 - Pedagogical Coherence Check
- `87301fe` - feat(knowledge-graph): implement Phase 3 - Knowledge Graph & Cross-Reference
- `03b9385` - feat: add frontend traceability UI for source citations

---

## Title Style System (IMPL√âMENT√â)

### Objectif
√âviter les titres de slides robotiques ("Introduction √† X", "Conclusion") et g√©n√©rer des titres qui sonnent humains, tout en supportant diff√©rents styles selon le contexte d'utilisation.

### Styles disponibles

| Style | Description | Use Case |
|-------|-------------|----------|
| `corporate` | Professionnel et formel | Formation entreprise |
| `engaging` | Dynamique, accrocheur | Cr√©ateurs de contenu |
| `expert` | Pr√©cision technique | Audiences avanc√©es |
| `mentor` | Chaleureux, p√©dagogique | Plateformes √©ducatives |
| `storyteller` | Narratif | Tutoriels, √©tudes de cas |
| `direct` | Clair, concis | Documentation |

### Anti-patterns d√©tect√©s

Le syst√®me d√©tecte et signale automatiquement les patterns robotiques:
- `introduction`: "Introduction √† X", "Pr√©sentation de X"
- `conclusion`: "Conclusion", "R√©sum√©", "Recap"
- `numbered`: "Partie 1", "Step 2:", "Section 3"
- `placeholder`: "Slide 1", "Title", "Untitled"
- `generic`: "What is X?", "Overview of X", "Basics of X"

### Architecture

```
services/presentation-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ presentation_models.py      # TitleStyle enum ajout√©
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ title_style_system.py       # TitleStyleSystem, validation, prompts
    ‚îî‚îÄ‚îÄ presentation_planner.py     # Int√©gration du syst√®me
```

### Frontend

```
frontend/src/app/dashboard/studio/courses/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ course-types.ts             # TitleStyle type, TITLE_STYLE_INFO
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ CourseForm.tsx              # S√©lecteur de style dans Advanced
‚îî‚îÄ‚îÄ page.tsx                        # Default: 'engaging'
```

### Utilisation

1. Le frontend envoie `title_style` dans la requ√™te
2. Le planner ajoute les guidelines de style au prompt GPT
3. Apr√®s g√©n√©ration, validation des titres avec logging des issues
4. Les anti-patterns sont signal√©s mais ne bloquent pas (monitoring)

### Commit

- `e7a71f1` - feat: implement Title Style System for human-quality slide titles

---

## SSVS - Synchronisation Audio-Vid√©o S√©mantique

### SSVS Algorithms (Impl√©ment√©)

Le syst√®me SSVS (Semantic Slide-Voiceover Synchronization) aligne pr√©cis√©ment l'audio et la vid√©o en utilisant l'analyse s√©mantique plut√¥t qu'une distribution proportionnelle simple.

**Architecture:**
```
services/presentation-generator/services/sync/
‚îú‚îÄ‚îÄ __init__.py                    # Exports publics
‚îú‚îÄ‚îÄ ssvs_algorithm.py              # SSVSSynchronizer principal
‚îú‚îÄ‚îÄ ssvs_calibrator.py             # Calibration multi-niveau
‚îî‚îÄ‚îÄ diagram_synchronizer.py        # Extension pour diagrammes
```

**Composants principaux:**

| Classe | R√¥le |
|--------|------|
| `SSVSSynchronizer` | Alignement s√©mantique slides ‚Üî voiceover |
| `SSVSCalibrator` | Correction des 5 sources de d√©synchronisation |
| `DiagramAwareSynchronizer` | Focus sur √©l√©ments de diagramme |
| `SemanticEmbeddingEngine` | Embeddings TF-IDF ou Sentence-BERT |
| `FocusAnimationGenerator` | G√©n√©ration keyframes d'animation |

### SSVS Calibrator (Janvier 2026)

Le calibrateur corrige **5 sources de d√©synchronisation audio-vid√©o:**

| Source | Offset par d√©faut | Description |
|--------|-------------------|-------------|
| **Global offset** | -300ms | D√©calage g√©n√©ral voix/image |
| **STT latency** | -50ms | Latence de transcription |
| **Semantic anticipation** | -150ms | Anticiper le slide avant le mot |
| **Transition duration** | 200ms | Temps de transition visuelle |
| **Visual inertia** | Variable | L'≈ìil a besoin de temps pour se fixer |

**Presets disponibles:**

| Preset | Usage | Caract√©ristiques |
|--------|-------|------------------|
| `default` | Standard | Offsets moyens |
| `fast_speech` | Speakers rapides | Anticipation r√©duite |
| `slow_speech` | Speakers lents | Plus de temps par slide |
| `technical_content` | Code, diagrammes | Slides plus longues |
| `simple_slides` | Texte simple | Transitions rapides |
| `live_presentation` | Style conf√©rence | Dynamique |
| `training_course` | **Formation Viralify** | Offset -400ms, anticipation -200ms |

**Fichiers:**
- `services/sync/ssvs_calibrator.py` - CalibrationConfig, SSVSCalibrator, CalibrationPresets
- `services/timeline_builder.py` - Int√©gration avec `calibration_preset` parameter

**Usage:**
```python
builder = TimelineBuilder(
    sync_method=SyncMethod.SSVS,
    calibration_preset="training_course"  # Preset optimis√© pour Viralify
)
```

### SSVS Embedding Engines (Janvier 2026)

Backends d'embedding configurables pour la synchronisation s√©mantique.

**Configuration:** `SSVS_EMBEDDING_BACKEND=auto|minilm|bge-m3|tfidf`

| Backend | Mod√®le | Dimensions | Taille | Qualit√© | Multilangue |
|---------|--------|------------|--------|---------|-------------|
| **minilm** | all-MiniLM-L6-v2 | 384 | ~80MB | ‚≠ê‚≠ê‚≠ê | üü° |
| **bge-m3** | BAAI/bge-m3 | 1024 | ~2GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ 100+ |
| **tfidf** | TF-IDF (local) | Variable | 0 | ‚≠ê‚≠ê | üü° |
| **auto** | MiniLM ‚Üí TF-IDF | - | - | Adaptatif | - |

**Ordre de priorit√© (mode auto):**
1. MiniLM (si sentence-transformers install√©)
2. TF-IDF (fallback sans d√©pendances)

**Architecture:**
```
services/sync/
‚îú‚îÄ‚îÄ embedding_engine.py        # NOUVEAU - Factory + backends
‚îÇ   ‚îú‚îÄ‚îÄ EmbeddingEngineBase (ABC)
‚îÇ   ‚îú‚îÄ‚îÄ TFIDFEmbeddingEngine
‚îÇ   ‚îú‚îÄ‚îÄ SentenceTransformerEngine (MiniLM/BGE-M3)
‚îÇ   ‚îî‚îÄ‚îÄ EmbeddingEngineFactory
‚îú‚îÄ‚îÄ ssvs_algorithm.py          # SSVSSynchronizer (modifi√©)
‚îî‚îÄ‚îÄ __init__.py                # Exports mis √† jour
```

**D√©pendances (optionnelles):**
```
# requirements.txt
sentence-transformers>=2.2.0  # Pour MiniLM et BGE-M3
torch>=2.0.0                  # CPU version
```

**Usage:**
```python
# Via SSVSSynchronizer
sync = SSVSSynchronizer(embedding_backend="minilm")

# Via factory directe
from services.sync import EmbeddingEngineFactory
engine = EmbeddingEngineFactory.create("auto")
```

### SSVS Sync Anchors (Janvier 2026)

Les **sync anchors** sont des contraintes dures qui forcent l'alignement √† des points pr√©cis.

**Format dans le voiceover:**
```
[SYNC:SLIDE_2] Passons maintenant au deuxi√®me sujet...
```

**Comportement:**
- L'anchor `[SYNC:SLIDE_2]` FORCE le slide 2 √† commencer exactement √† ce mot
- L'algorithme partitionne le probl√®me aux points d'anchor
- Chaque partition est r√©solue ind√©pendamment par DP

**Flux d'impl√©mentation:**
```
[SYNC:SLIDE_2] dans voiceover
       ‚Üì
_find_sync_anchors() extrait les anchors (timeline_builder.py)
       ‚Üì
_convert_to_ssvs_anchors() convertit en SSVSSyncAnchor
       ‚Üì
synchronize_with_anchors() utilise comme CONTRAINTE DURE
       ‚Üì
_create_anchor_partitions() divise le probl√®me DP
       ‚Üì
R√©sultat: slide align√© exactement √† l'anchor
```

**Dataclass SyncAnchor:**
```python
@dataclass
class SyncAnchor:
    slide_index: int      # Slide concern√©
    timestamp: float      # Timestamp cible (secondes)
    segment_index: int    # Segment vocal correspondant
    anchor_type: str      # SLIDE, CODE, DIAGRAM
    anchor_id: str        # "SLIDE_2"
    tolerance_ms: float   # Tol√©rance (d√©faut: 500ms)
```

**R√©sultat avec anchor_used:**
```python
@dataclass
class SynchronizationResult:
    # ... existing fields ...
    anchor_used: Optional[SyncAnchor] = None  # Si ancr√©
```

**Test de validation:**
```
Sans anchors:  Slide 2: 5.5s - 9.0s
Avec anchor:   Slide 2: 5.5s - 9.0s [ANCHORED] ‚Üê Contrainte respect√©e
```

**Fichiers modifi√©s:**
- `services/sync/ssvs_algorithm.py` - SyncAnchor, synchronize_with_anchors()
- `services/timeline_builder.py` - _convert_to_ssvs_anchors(), _find_segment_for_timestamp()
- `services/sync/__init__.py` - Export SyncAnchor

### SSVS Partition Fix (Janvier 2026)

**Probl√®me:** Quand plusieurs anchors mappaient vers le m√™me segment audio, des slides √©taient ignor√©s dans la timeline, causant une d√©synchronisation audio-vid√©o.

**Sympt√¥me observ√© dans les logs:**
```
[TIMELINE] Anchor slide_001: slide 0 -> segment 0 @ 0.00s
[TIMELINE] Anchor slide_002: slide 1 -> segment 0 @ 24.18s   <-- M√äME segment!
[SSVS] Created 6 partitions from anchors  <-- Devrait √™tre 8!
[TIMELINE] SSVS Slide 1: 0.000s - 23.368s
[TIMELINE] SSVS Slide 2: 23.378s - 59.930s
[TIMELINE] SSVS Slide 4: 59.940s - 73.288s   <-- Slide 3 MANQUANT!
```

**Cause racine:** Dans `_create_anchor_partitions()`, la condition `end_seg > start_seg` √©chouait quand `end_seg == start_seg` (plusieurs slides mapp√©s au m√™me segment), causant le skip de la partition.

**Fix appliqu√© dans `ssvs_algorithm.py`:**
1. **Tri des boundaries** par slide_index pour ordre correct
2. **Suppression des duplicates** de slide_index (garder le premier)
3. **Gestion edge case** o√π `end_seg <= start_seg` en ajustant les bornes de partition
4. **V√©rification de couverture** avec fallback pour slides manquants
5. **Logging am√©lior√©** pour d√©tecter les probl√®mes

**Code ajout√©:**
```python
# Sort boundaries by slide_index to ensure proper ordering
boundaries.sort(key=lambda b: (b[0], b[1]))

# Remove duplicate slide indices (keep the first one)
seen_slides = set()
unique_boundaries = []
for slide_idx, seg_idx, anchor in boundaries:
    if slide_idx not in seen_slides:
        unique_boundaries.append((slide_idx, seg_idx, anchor))
        seen_slides.add(slide_idx)

# Handle case where multiple slides map to same segment
if n_segments_in_partition <= 0:
    n_segments_in_partition = min(n_slides_in_partition, n_segments - start_seg)
    # ... adjusted partition creation
```

**Fichier modifi√©:**
- `services/presentation-generator/services/sync/ssvs_algorithm.py` - `_create_anchor_partitions()` r√©√©crite

---

## Direct Sync - Option B+ (Janvier 2026)

### Probl√®me r√©solu

SSVS (post-hoc matching) avait des limitations:
- D√©pendance Whisper pour les timestamps (¬±200ms d'erreur)
- Drift cumulatif malgr√© la calibration
- Matching s√©mantique parfois inexact
- Transitions de slides ne respectant pas les phrases de transition

### Solution: TTS par slide + Crossfade

**Principe:** Synchronisation PARFAITE par construction.

```
AVANT (complexe, fragile):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Planner ‚Üí Script complet ‚Üí TTS (1 appel) ‚Üí Whisper ‚Üí SSVS ‚Üí Calibration ‚Üí Timeline
                                              ‚Üì
                                    Source d'erreurs multiples

APR√àS (simple, robuste):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Planner ‚Üí Scripts par slide ‚Üí TTS (N appels //) ‚Üí Concat + Crossfade ‚Üí Timeline directe
                                                          ‚Üì
                                              Synchronisation PARFAITE
```

### Nouveaux composants

**1. SlideAudioGenerator** (`services/slide_audio_generator.py`)
- G√©n√®re TTS pour chaque slide en parall√®le (async)
- Rate limiting avec semaphore (max 5 concurrent)
- Cache des audios g√©n√©r√©s
- Retourne `SlideAudioBatch` avec dur√©es exactes

**2. AudioConcatenator** (`services/audio_concatenator.py`)
- Concat√®ne les audios avec crossfade FFmpeg (100ms)
- √âlimine les micro-pauses entre slides
- Normalise le volume
- Timeline ajust√©e pour le crossfade

**3. DirectTimelineBuilder** (`services/direct_timeline_builder.py`)
- Construit la timeline √† partir des dur√©es audio
- Pas de SSVS, pas de matching s√©mantique
- Sync quality: PARFAITE (by construction)

### Configuration

```env
# Activer Direct Sync (recommand√©, d√©faut: true)
USE_DIRECT_SYNC=true

# Fallback vers SSVS si d√©sactiv√©
USE_DIRECT_SYNC=false
```

### Avantages

| Crit√®re | SSVS (avant) | Direct Sync (apr√®s) |
|---------|--------------|---------------------|
| Synchronisation | ¬±200ms | **PARFAITE** |
| D√©pendance Whisper | Oui | **Non** |
| Calibration n√©cessaire | Oui | **Non** |
| Debug facile | Non | **Oui** |
| Transitions naturelles | Variable | **Avec crossfade** |

### Fichiers cr√©√©s/modifi√©s

**Nouveaux fichiers:**
- `services/presentation-generator/services/slide_audio_generator.py`
- `services/presentation-generator/services/audio_concatenator.py`
- `services/presentation-generator/services/direct_timeline_builder.py`

**Fichiers modifi√©s:**
- `services/presentation-generator/services/presentation_compositor.py`
  - Ajout de `_generate_voiceover_direct()`
  - Ajout de `_compose_video_with_direct_timeline()`
  - Flag `use_direct_sync` pour basculer entre modes

---

## VoiceoverEnforcer - Expansion des voiceovers courts (Janvier 2026)

### Probl√®me r√©solu

Les voiceovers g√©n√©r√©s par le planner sont parfois trop courts pour la dur√©e cible, causant des vid√©os de 2 minutes au lieu des 5-10 minutes demand√©es.

### Solution: Post-validation + Expansion automatique

Le `VoiceoverEnforcer` valide et enrichit les voiceovers APR√àS la g√©n√©ration initiale:

1. **Validation**: V√©rifie que chaque slide atteint le nombre de mots requis (2.5 mots/sec)
2. **Expansion**: Utilise un LLM l√©ger (gpt-4o-mini) pour enrichir les slides trop courtes
3. **Pr√©servation**: Garde les sync anchors `[SYNC:...]` et le sens original

### Param√®tres de validation

| Param√®tre | Valeur | Description |
|-----------|--------|-------------|
| `WORDS_PER_SECOND` | 2.5 | Vitesse de parole standard (150 mots/min) |
| `MIN_WORDS_PER_SLIDE` | 40 | Minimum absolu par slide |
| `VALIDATION_THRESHOLD` | 0.75 | 75% du requis = valide |

### Multiplicateurs par type de slide

| Type | Multiplicateur | Raison |
|------|----------------|--------|
| `title` | 0.5√ó | Slides de titre peuvent √™tre plus courts |
| `conclusion` | 0.8√ó | R√©sum√© concis |
| `content` | 1.0√ó | Standard |
| `code` | 1.2√ó | Code n√©cessite plus d'explication |
| `code_demo` | 1.2√ó | D√©mo n√©cessite walkthrough |
| `diagram` | 1.3√ó | Diagrammes n√©cessitent description d√©taill√©e |

### Architecture

```
services/presentation-generator/services/
‚îî‚îÄ‚îÄ voiceover_enforcer.py
    ‚îú‚îÄ‚îÄ VoiceoverValidation    # R√©sultat de validation par slide
    ‚îú‚îÄ‚îÄ EnforcementResult      # R√©sultat global
    ‚îú‚îÄ‚îÄ VoiceoverEnforcer      # Classe principale
    ‚îÇ   ‚îú‚îÄ‚îÄ validate_script()        # Valide toutes les slides
    ‚îÇ   ‚îú‚îÄ‚îÄ expand_short_voiceovers() # √âtend les slides trop courtes
    ‚îÇ   ‚îî‚îÄ‚îÄ _expand_voiceover()      # Expansion d'une slide
    ‚îî‚îÄ‚îÄ enforce_voiceover_duration() # Fonction de convenance
```

### Int√©gration dans le pipeline

```python
# Dans generate_script_with_validation() de presentation_planner.py

# 1. G√©n√©ration initiale par LLM
script_data = await self.client.chat.completions.create(...)

# 2. Validation slide count + regeneration si insuffisant
script_data = await self._validate_and_regenerate_if_needed(...)

# 3. NOUVEAU: Enforcement des dur√©es voiceover
script_data, enforcement_result = await enforce_voiceover_duration(
    script_data=script_data,
    target_duration=request.duration,
    content_language=content_language,
    client=self.client
)
```

### Logs serveur

```
[ENFORCER] Validation: 580/750 words, 3/10 slides need expansion
[ENFORCER] 3/10 voiceovers too short, expanding...
[ENFORCER] Slide 2 (content): 45 -> 78 words
[ENFORCER] Slide 5 (diagram): 38 -> 95 words
[ENFORCER] Slide 8 (code): 52 -> 88 words
[ENFORCER] Expansion complete: 580 -> 742 words (99%)
[PLANNER] ENFORCER: Expanded 3/10 slides
[PLANNER] ENFORCER: 580 -> 742 words (99%)
```

### Configuration

```env
# Mod√®le utilis√© pour l'expansion (l√©ger et rapide)
VOICEOVER_EXPANSION_MODEL=gpt-4o-mini
```

### Fichiers cr√©√©s/modifi√©s

**Nouveau fichier:**
- `services/presentation-generator/services/voiceover_enforcer.py`

**Fichier modifi√©:**
- `services/presentation-generator/services/presentation_planner.py`
  - Import de `enforce_voiceover_duration`
  - Appel apr√®s `_validate_and_regenerate_if_needed()`

**Commit:** `7450cec` - feat(voiceover): add VoiceoverEnforcer to expand short voiceovers

---

## Phase 7B - Multi-Provider LLM & Training Data (Janvier 2026)

### Multi-Provider LLM Support

Support de 8 providers LLM avec configuration unifi√©e.

**Providers disponibles:**

| Provider | Mod√®le par d√©faut | Max Context | Usage recommand√© |
|----------|-------------------|-------------|------------------|
| **OpenAI** | gpt-4o | 128K | Qualit√© maximale |
| **DeepSeek** | deepseek-chat | 64K | 90% moins cher qu'OpenAI |
| **Groq** | llama-3.3-70b-versatile | 128K | Ultra-rapide (inference) |
| **Mistral** | mistral-large | 32K | Bon pour contenu fran√ßais |
| **Together AI** | Llama-3.1-405B | 128K | Grands mod√®les |
| **xAI (Grok)** | grok-2 | 128K | Context window 2M |
| **Ollama** | llama3.1:70b | 32K | Self-hosted (gratuit) |
| **RunPod** | llama-3.1-70b | 32K | Self-hosted GPU |

**Architecture:**
```
services/shared/
‚îú‚îÄ‚îÄ __init__.py              # Exports publics
‚îî‚îÄ‚îÄ llm_provider.py          # LLMProvider enum, ProviderConfig, LLMClientFactory
```

**Configuration:**
```env
# Choisir le provider
LLM_PROVIDER=groq

# Cl√©s API par provider
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk_...
DEEPSEEK_API_KEY=sk-...
MISTRAL_API_KEY=...
TOGETHER_API_KEY=...
XAI_API_KEY=xai-...

# Pour self-hosted (Ollama/RunPod)
OLLAMA_HOST=http://localhost:11434
RUNPOD_ENDPOINT_ID=your_endpoint_id
RUNPOD_API_KEY=...
LLM_TIMEOUT=120  # Configurable
```

**Usage dans le code:**
```python
from services.shared import LLMClientFactory, LLMProvider

# Cr√©ation automatique selon LLM_PROVIDER
client, model = LLMClientFactory.create()

# Ou forcer un provider sp√©cifique
client, model = LLMClientFactory.create(LLMProvider.GROQ)
```

---

### Training Logger (Fine-tuning Data Collection)

Syst√®me de collecte de donn√©es d'entra√Ænement pour le fine-tuning de mod√®les.

**Objectif:** Capturer automatiquement toutes les interactions LLM valid√©es pour cr√©er un dataset de fine-tuning.

**Architecture:**
```
services/shared/
‚îú‚îÄ‚îÄ __init__.py              # Exports: TrainingLogger, TaskType, log_training_example
‚îî‚îÄ‚îÄ training_logger.py       # TrainingLogger class
```

**TaskType Enum:**
```python
class TaskType(str, Enum):
    COURSE_PLANNING = "course_planning"
    PRESENTATION_SCRIPT = "presentation_script"
    SLIDE_GENERATION = "slide_generation"
    DIAGRAM_GENERATION = "diagram_generation"
    CODE_GENERATION = "code_generation"
    QUIZ_GENERATION = "quiz_generation"
    TRANSLATION = "translation"
    RAG_RETRIEVAL = "rag_retrieval"
```

**Format JSONL:**
```json
{
  "id": "uuid",
  "timestamp": "2026-01-25T10:30:00Z",
  "task_type": "presentation_script",
  "provider": "groq",
  "model": "llama-3.3-70b-versatile",
  "messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "..."}],
  "response": "...",
  "input_tokens": 1500,
  "output_tokens": 800,
  "metadata": {"topic": "Apache Kafka", "audience": "senior"}
}
```

**Configuration:**
```env
TRAINING_LOGGER_ENABLED=true
TRAINING_DATA_PATH=/app/data/training_dataset.jsonl
```

**Volume Docker:**
```yaml
volumes:
  training_data:

services:
  presentation-generator:
    volumes:
      - training_data:/app/data
```

**Usage:**
```python
from services.shared import log_training_example, TaskType

# Logger une interaction valid√©e
log_training_example(
    messages=[...],
    response="...",
    task_type=TaskType.PRESENTATION_SCRIPT,
    model="llama-3.3-70b-versatile",
    provider="groq",
    metadata={"topic": "Kafka"}
)
```

**Export pour OpenAI fine-tuning:**
```python
from services.shared import TrainingLogger

logger = TrainingLogger()
logger.export_for_openai("/app/data/openai_finetune.jsonl")
```

---

### RAG Verifier v4 - Support Multilingue (Janvier 2026)

**Probl√®me r√©solu:** Le RAG Verifier v3 √©chouait sur le contenu cross-langue (documents source en anglais, g√©n√©ration en fran√ßais) car les topics "integration" ‚â† "int√©gration" ne matchaient pas.

**Solution:** Embeddings multilingues E5-large + d√©tection automatique de langue + mode semantic-only pour cross-langue.

**Nouveau backend E5-Large:**

| Backend | Mod√®le | Dimensions | Multilangue | Qualit√© |
|---------|--------|------------|-------------|---------|
| **e5-large** | intfloat/multilingual-e5-large | 1024 | ‚úÖ 100+ langues | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| minilm | all-MiniLM-L6-v2 | 384 | üü° anglais | ‚≠ê‚≠ê‚≠ê |
| bge-m3 | BAAI/bge-m3 | 1024 | ‚úÖ 100+ | ‚≠ê‚≠ê‚≠ê‚≠ê |
| tfidf | TF-IDF local | Variable | üü° | ‚≠ê‚≠ê |

**Caract√©ristiques E5-Large:**
- Entra√Æn√© sur 100+ langues avec alignement cross-lingue
- "query: " prefix pour meilleure performance
- Embeddings fran√ßais et anglais dans le M√äME espace vectoriel
- "integration" et "int√©gration" ont une similarit√© ~0.85

**Configuration:**
```env
# Mode: auto (d√©tecte cross-language), semantic_only, comprehensive
RAG_VERIFIER_MODE=auto

# Backend: e5-large (recommand√©), minilm, bge-m3, tfidf
RAG_EMBEDDING_BACKEND=e5-large
```

**Architecture:**
```
services/presentation-generator/services/
‚îú‚îÄ‚îÄ rag_verifier.py              # RAGVerifier v4 avec d√©tection de langue
‚îî‚îÄ‚îÄ sync/
    ‚îî‚îÄ‚îÄ embedding_engine.py      # E5-Large backend ajout√©
```

**D√©tection de langue:**
```python
def _detect_language(self, text: str) -> str:
    """Simple language detection based on common words"""
    french_words = {'le', 'la', 'les', 'de', 'du', 'des', 'et', 'en', ...}
    english_words = {'the', 'a', 'an', 'is', 'are', 'of', 'and', 'to', ...}
    # Count occurrences and return 'fr' or 'en'
```

**Mode cross-langue automatique:**
```python
def verify_comprehensive(self, generated_content, source_documents, verbose=False):
    # Detect if source and generated are different languages
    if self._is_cross_language(source_text, generated_text):
        # Use semantic-only mode (skip keyword/topic matching)
        return self._verify_semantic_only(generated_content, source_documents)
    else:
        # Full verification with keywords + topics + semantic
        return self._verify_full(generated_content, source_documents)
```

**Seuils adapt√©s:**

| Mode | Seuil s√©mantique | Keywords | Topics |
|------|------------------|----------|--------|
| Same language | 45% | ‚úÖ Oui | ‚úÖ Oui |
| Cross-language | 35% | ‚ùå Skip | ‚ùå Skip |

**Logs serveur:**
```
[RAG_VERIFY] Detected cross-language: source=en, generated=fr
[RAG_VERIFY] Using semantic-only mode for cross-language verification
[RAG_VERIFY] E5-Large similarity: 0.78 (threshold: 0.35)
[RAG_VERIFY] ‚úÖ RAG COMPLIANT: 78% semantic coverage
```

**Fichiers modifi√©s:**
- `services/sync/embedding_engine.py` - Ajout E5-Large backend
- `services/rag_verifier.py` - D√©tection langue + mode semantic-only
- `docker-compose.yml` - Variables RAG_VERIFIER_MODE, RAG_EMBEDDING_BACKEND
- `.env.example` - Documentation des nouvelles variables

**Commit:** `db3b2c8` - feat: RAG Verifier v4 with multilingual E5-large support

---

### WeaveGraph - Graphe de Concepts (Phase 2)

Syst√®me de graphe s√©mantique qui d√©couvre automatiquement les relations entre concepts extraits des documents, permettant une expansion de requ√™tes pour une meilleure v√©rification RAG.

**Objectif:** Am√©liorer la qualit√© du matching RAG en comprenant que "Kafka" ‚Üî "message broker" ‚Üî "event streaming" sont des concepts reli√©s.

**Architecture:**
```
services/presentation-generator/services/weave_graph/
‚îú‚îÄ‚îÄ __init__.py              # Exports publics
‚îú‚îÄ‚îÄ models.py                # ConceptNode, ConceptEdge, WeaveGraph, QueryExpansion
‚îú‚îÄ‚îÄ concept_extractor.py     # Extraction NLP + regex patterns
‚îú‚îÄ‚îÄ graph_builder.py         # Construction du graphe avec E5-large embeddings
‚îî‚îÄ‚îÄ pgvector_store.py        # Stockage PostgreSQL + pgvector
```

**Mod√®les de donn√©es:**

```python
class ConceptNode:
    id: str
    name: str                    # "Apache Kafka"
    canonical_name: str          # "apache_kafka"
    language: str                # "en" ou "fr"
    embedding: List[float]       # E5-large 1024-dim
    source_document_ids: List[str]
    frequency: int               # Nombre d'occurrences
    aliases: List[str]

class ConceptEdge:
    source_id: str
    target_id: str
    relation_type: RelationType  # similar, translation, part_of, prerequisite
    weight: float                # Force de la relation (0-1)
    bidirectional: bool

class QueryExpansion:
    original_query: str
    expanded_terms: List[str]    # Termes enrichis via le graphe
    expansion_paths: Dict        # Chemins de l'expansion
    languages_covered: Set[str]  # Langues couvertes
```

**Tables pgvector:**

```sql
-- Concepts avec embeddings E5-large
CREATE TABLE weave_concepts (
    id UUID PRIMARY KEY,
    canonical_name VARCHAR(255),
    name VARCHAR(500),
    language VARCHAR(10),
    embedding vector(1024),      -- E5-large multilingual
    source_document_ids TEXT[],
    frequency INT,
    user_id VARCHAR(255),
    UNIQUE(canonical_name, user_id)
);

-- Relations entre concepts
CREATE TABLE weave_edges (
    source_concept_id UUID REFERENCES weave_concepts(id),
    target_concept_id UUID REFERENCES weave_concepts(id),
    relation_type VARCHAR(50),   -- similar, translation, part_of
    weight FLOAT,                -- 0-1
    UNIQUE(source_concept_id, target_concept_id, relation_type)
);
```

**Flux de construction:**

```
1. Upload document ‚Üí ConceptExtractor.extract_concepts()
   - Patterns regex (CamelCase, snake_case, acronymes)
   - TF-IDF pour keywords importants
   - Termes de domaine tech connus

2. Pour chaque concept ‚Üí E5-large embedding ‚Üí pgvector INSERT

3. GraphBuilder.build_edges()
   - Similarit√© cosine entre embeddings
   - Seuil: 0.70 (same language), 0.80 (cross-language)
   - Max 10 edges par concept

4. RAG Verifier ‚Üí WeaveGraphBuilder.expand_query("Kafka")
   ‚Üí ["Kafka", "message broker", "consumer", "producer", "file d'attente"]
```

**Int√©gration RAG Verifier v5:**

```python
# Dans verify_comprehensive()
if self._weave_graph_enabled:
    # Expand query terms using the graph
    expanded_terms, boost = self._expand_with_weave_graph_sync(terms, user_id)

    # Apply boost to coverage (max +15%)
    boosted_coverage = min(1.0, coverage + boost)
```

**Configuration:**

```env
# Activer WeaveGraph
WEAVE_GRAPH_ENABLED=true

# Variables database (pour pgvector)
DATABASE_HOST=postgres
DATABASE_PORT=5432
DATABASE_USER=tiktok_user
DATABASE_PASSWORD=...
DATABASE_NAME=tiktok_platform
```

**D√©pendances ajout√©es:**
- `asyncpg>=0.29.0` dans requirements.txt

**RelationType enum:**

| Type | Description |
|------|-------------|
| `similar` | Similarit√© s√©mantique (embedding >0.7) |
| `translation` | √âquivalent cross-langue (EN‚ÜîFR) |
| `part_of` | Concept fait partie d'un autre |
| `prerequisite` | Concept pr√©requis |
| `synonym` | M√™me signification |
| `hypernym` | Concept plus g√©n√©ral |
| `hyponym` | Concept plus sp√©cifique |

**Logs serveur:**

```
[WEAVE_GRAPH] Building graph from 5 documents
[WEAVE_GRAPH] Extracted 127 unique concepts
[WEAVE_GRAPH] Generated 127/127 embeddings
[WEAVE_GRAPH] Stored 127 concepts with embeddings
[WEAVE_GRAPH] Built 342 similarity edges
[RAG_VERIFIER] WeaveGraph expanded 12 -> 28 terms (+6% boost)
```

---

### Resonate Match - Propagation de R√©sonance (Phase 3)

Syst√®me de propagation de scores √† travers le graphe de concepts. Quand un concept matche directement, ses voisins re√ßoivent un score de "r√©sonance" proportionnel √† la force de leur connexion.

**Principe:**
```
Query: "Kafka consumer"
         ‚Üì match direct (1.0)
    [consumer] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
         ‚îÇ                                  ‚îÇ
         ‚îÇ edge (0.85)                     ‚îÇ edge (0.75)
         ‚Üì                                  ‚Üì
    [Kafka] ‚Üê‚îÄ‚îÄ r√©sonance 0.60        [producer] ‚Üê‚îÄ‚îÄ r√©sonance 0.52
         ‚îÇ
         ‚îÇ edge (0.70)
         ‚Üì
    [message broker] ‚Üê‚îÄ‚îÄ r√©sonance 0.42
```

**Algorithme multi-hop avec decay:**
```python
resonance(neighbor) = parent_score √ó edge_weight √ó decay^depth

# Configuration par d√©faut
decay = 0.7       # Score decay par hop
max_depth = 3     # Profondeur maximum
min_resonance = 0.10  # Seuil minimum pour continuer
```

**Architecture:**
```
services/presentation-generator/services/weave_graph/
‚îî‚îÄ‚îÄ resonance_matcher.py    # ResonanceMatcher, ResonanceConfig, ResonanceResult
```

**Classes principales:**

```python
@dataclass
class ResonanceConfig:
    decay_factor: float = 0.7           # Score decay per hop
    max_depth: int = 3                  # Maximum propagation depth
    min_resonance: float = 0.10         # Minimum score to propagate
    boost_translation: float = 1.2      # Boost for cross-language edges
    boost_synonym: float = 1.1          # Boost for synonym edges
    max_resonating_concepts: int = 50   # Limit total concepts

@dataclass
class ResonanceResult:
    scores: Dict[str, float]            # concept_id -> resonance score
    depths: Dict[str, int]              # concept_id -> depth reached
    paths: Dict[str, List[str]]         # concept_id -> path from match
    direct_matches: int
    propagated_matches: int
    total_resonance: float
    max_depth_reached: int
```

**Int√©gration RAG Verifier v6:**

```python
# Dans verify_comprehensive()
if self._resonance_enabled and self._resonance_matcher:
    resonance_result = self._compute_resonance_sync(
        generated_terms, source_terms, user_id
    )
    resonance_boost = resonance_result['boost']  # Max +15%

# Boost combin√©
total_boost = expansion_boost + resonance_boost
boosted_coverage = min(1.0, coverage + total_boost)
```

**Configuration:**

```env
# Activer la r√©sonance
RESONANCE_ENABLED=true

# Param√®tres de propagation
RESONANCE_DECAY=0.7      # Decay par hop (0-1)
RESONANCE_MAX_DEPTH=3    # Profondeur max (1-5)
```

**Boosts par type de relation:**

| RelationType | Boost |
|--------------|-------|
| `translation` | √ó1.2 |
| `synonym` | √ó1.1 |
| `similar` | √ó1.0 |
| `part_of` | √ó1.0 |

**Logs serveur:**

```
[RAG_VERIFIER] Resonance: 5 direct, 12 propagated, +8% boost
[RAG_VERIFIER] ‚úÖ RAG COMPLIANT (SEMANTIC+WeaveGraph+Resonance): 72% semantic similarity
```

**Fichiers modifi√©s:**
- `services/weave_graph/resonance_matcher.py` (CR√â√â)
- `services/weave_graph/__init__.py` - Exports ResonanceMatcher
- `services/rag_verifier.py` - RAG Verifier v6 avec resonance
- `docker-compose.yml` - Variables RESONANCE_*
- `.env.example` - Documentation variables

---

## Phase 7 - VQV-HALLU: Voice Quality Verification (IMPL√âMENT√â)

### Objectif
D√©tecter les hallucinations audio dans les voiceovers g√©n√©r√©s par TTS (ElevenLabs) avant composition vid√©o.

### Architecture (4 Layers)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           VQV-HALLU PIPELINE                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Audio   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ              LAYER 1: ACOUSTIC ANALYZER              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Input   ‚îÇ    ‚îÇ  ‚Ä¢ Spectral Anomaly Detection (distortion, noise)   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚Ä¢ Click/Pop Detection, Silence Analysis            ‚îÇ   ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                            ‚ñº                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Text    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ              LAYER 2: LINGUISTIC COHERENCE          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Source  ‚îÇ    ‚îÇ  ‚Ä¢ ASR Reverse Transcription (Whisper large-v3)     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚Ä¢ Gibberish Detection, Language Consistency        ‚îÇ   ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                            ‚ñº                                ‚îÇ
‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                  ‚îÇ              LAYER 3: SEMANTIC ALIGNMENT            ‚îÇ   ‚îÇ
‚îÇ                  ‚îÇ  ‚Ä¢ Embedding Similarity (sentence-transformers)     ‚îÇ   ‚îÇ
‚îÇ                  ‚îÇ  ‚Ä¢ Hallucination Boundary Detection                 ‚îÇ   ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                            ‚ñº                                ‚îÇ
‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                  ‚îÇ              LAYER 4: SCORE FUSION ENGINE           ‚îÇ   ‚îÇ
‚îÇ                  ‚îÇ  ‚Ä¢ Weighted Ensemble + Cross-Layer Patterns         ‚îÇ   ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                            ‚ñº                                ‚îÇ
‚îÇ                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ                            ‚îÇ   QUALITY SCORE (0-100)  ‚îÇ                    ‚îÇ
‚îÇ                            ‚îÇ   + Action Recommendation‚îÇ                    ‚îÇ
‚îÇ                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Feature Flags (d√©sactivable)

```bash
# Variables d'environnement
VQV_HALLU_ENABLED=true/false  # Activer/d√©sactiver le service
VQV_STRICT_MODE=false         # Si true, bloque sur erreur; si false, accepte par d√©faut
VQV_MIN_SCORE=70              # Score minimum acceptable
VQV_MAX_REGEN=3               # Tentatives de r√©g√©n√©ration max
```

### Graceful Degradation

Le service est con√ßu pour ne jamais bloquer la g√©n√©ration:
- Si `VQV_HALLU_ENABLED=false` ‚Üí audio accept√© sans validation
- Si service indisponible ‚Üí audio accept√© avec warning
- Si erreur d'analyse ‚Üí audio accept√© en mode non-strict
- Circuit breaker apr√®s 5 √©checs cons√©cutifs

### Endpoints API

| Endpoint | Description |
|----------|-------------|
| `GET /health` | Health check avec status mod√®les |
| `GET /api/v1/status` | Status d√©taill√© + statistiques |
| `POST /api/v1/analyze` | Analyse un voiceover |
| `POST /api/v1/analyze/batch` | Analyse plusieurs voiceovers |
| `POST /api/v1/analyze/upload` | Analyse fichier upload√© |
| `GET /api/v1/config/content-types` | Types de contenu et seuils |

### Int√©gration dans le Pipeline Voiceover (slide_audio_generator.py)

Le service VQV-HALLU est int√©gr√© directement dans `SlideAudioGenerator`:

```python
# Initialisation avec param√®tres VQV
generator = SlideAudioGenerator(
    voice_id="alloy",
    language="fr",
    vqv_enabled=True,        # Activer validation VQV
    vqv_max_attempts=3,      # Max r√©g√©n√©rations si √©chec
    vqv_min_score=70.0,      # Score minimum acceptable
)

# G√©n√©ration batch avec validation automatique
batch = await generator.generate_batch(slides, job_id="course_123")

# Chaque SlideAudio contient les r√©sultats VQV
for audio in batch.slide_audios:
    print(f"Slide {audio.slide_index}: validated={audio.vqv_validated}, score={audio.vqv_score}")
    if audio.vqv_issues:
        print(f"  Issues: {audio.vqv_issues}")

# Log automatique en fin de batch:
# [SLIDE_AUDIO] VQV Summary: 8/10 validated, avg_score=82.3, attempts=14, issues=2
```

**Flux de validation:**
1. Audio g√©n√©r√© par TTS
2. Si `VQV_HALLU_ENABLED=true` ‚Üí validation via VQVHalluClient
3. Si score < 70 ‚Üí suppression audio et r√©g√©n√©ration (max 3 tentatives)
4. Si 3 √©checs ‚Üí audio accept√© avec warning (graceful degradation)
5. R√©sultats stock√©s dans `SlideAudio.vqv_*` fields

**Champs SlideAudio ajout√©s:**
| Champ | Type | Description |
|-------|------|-------------|
| `vqv_validated` | bool | Audio valid√© par VQV |
| `vqv_score` | float | Score final (0-100) |
| `vqv_attempts` | int | Nombre de tentatives |
| `vqv_issues` | List[str] | Probl√®mes d√©tect√©s |

### Utilisation directe du client

```python
from services.vqv_hallu_client import validate_voiceover

result = await validate_voiceover(
    source_text="Le texte source du voiceover",
    audio_url="https://storage.example.com/audio.mp3",
    audio_id="slide_001",
    content_type="technical_course",
    language="fr",
)

if result.should_regenerate:
    # Score < 70, r√©g√©n√©rer le voiceover
    print(f"Issues: {result.primary_issues}")
else:
    # Audio acceptable
    pass
```

### Fichiers cr√©√©s

```
services/vqv-hallu/
‚îú‚îÄ‚îÄ main.py                    # FastAPI service
‚îú‚îÄ‚îÄ client.py                  # Client library
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ analyzers/
‚îÇ   ‚îú‚îÄ‚îÄ acoustic_analyzer.py   # Layer 1
‚îÇ   ‚îú‚îÄ‚îÄ linguistic_analyzer.py # Layer 2
‚îÇ   ‚îî‚îÄ‚îÄ semantic_analyzer.py   # Layer 3
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py            # Orchestration
‚îÇ   ‚îî‚îÄ‚îÄ score_fusion.py        # Layer 4
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ data_models.py         # Structures de donn√©es
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ settings.py            # Configuration et seuils
```

---

## Phase 8 - MAESTRO Engine Integration (IMPL√âMENT√â)

### Objectif

Int√©gration du syst√®me MAESTRO (Multi-level Adaptive Educational Structuring & Teaching Resource Orchestrator) pour la g√©n√©ration de cours avanc√©e avec:
- **Calibration 4D de difficult√©** (conceptual_complexity, prerequisites_depth, information_density, cognitive_load)
- **Taxonomie de Bloom** align√©e sur les quiz et exercices
- **Progression fluide** (max 15% de saut de difficult√© entre concepts)
- **Script segment√©** (intro, explanation, example, summary)

### Architecture (5 Layers Pipeline)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         MAESTRO 5-LAYER PIPELINE                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  Layer 1: DOMAIN DISCOVERY                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Analyse du sujet et identification des th√®mes                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Extraction des objectifs d'apprentissage                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ D√©tection des pr√©requis                                          ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                   ‚Üì                                         ‚îÇ
‚îÇ  Layer 2: KNOWLEDGE GRAPH                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Construction du graphe de pr√©requis                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Tri topologique (Kahn's algorithm)                               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ D√©tection et r√©solution des cycles                               ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                   ‚Üì                                         ‚îÇ
‚îÇ  Layer 3: DIFFICULTY CALIBRATION                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Vecteur 4D de difficult√© par concept                             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Score composite pond√©r√©                                          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Mapping vers SkillLevel et BloomLevel                            ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                   ‚Üì                                         ‚îÇ
‚îÇ  Layer 4: CURRICULUM SEQUENCING                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Ordre d'apprentissage optimal                                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Progression fluide (max 15% jump)                                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Groupement en modules                                            ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                   ‚Üì                                         ‚îÇ
‚îÇ  Layer 5: CONTENT GENERATION                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Scripts segment√©s (intro, explanation, example, summary)         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Quiz align√©s sur Bloom's Taxonomy                                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Exercices pratiques avec solutions                               ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Modes de G√©n√©ration

| Mode | Description | Utilisation |
|------|-------------|-------------|
| **RAG** | Utilise les documents upload√©s | Cours bas√© sur contenu existant |
| **MAESTRO** | Pipeline 5 couches sans documents | Cours g√©n√©r√©s √† partir de z√©ro |
| **HYBRID** | (Futur) Combine RAG + MAESTRO | Meilleur des deux mondes |

### Vecteur de Difficult√© 4D

```python
@dataclass
class DifficultyVector:
    conceptual_complexity: float  # 0.0-1.0 - Niveau d'abstraction
    prerequisites_depth: float    # 0.0-1.0 - Profondeur des pr√©requis
    information_density: float    # 0.0-1.0 - Quantit√© d'information
    cognitive_load: float         # 0.0-1.0 - Effort mental requis

    # Pond√©ration par d√©faut
    WEIGHTS = {
        "conceptual_complexity": 0.25,
        "prerequisites_depth": 0.20,
        "information_density": 0.25,
        "cognitive_load": 0.30,
    }

    @property
    def composite_score(self) -> float:
        return sum(self.WEIGHTS[k] * getattr(self, k) for k in self.WEIGHTS)
```

### Skill Levels & Bloom's Taxonomy

**Skill Levels:**

| Level | Score Range | Description |
|-------|-------------|-------------|
| BEGINNER | 0.00-0.20 | Concepts fondamentaux |
| INTERMEDIATE | 0.20-0.40 | Application pratique |
| ADVANCED | 0.40-0.60 | Analyse complexe |
| VERY_ADVANCED | 0.60-0.80 | √âvaluation critique |
| EXPERT | 0.80-1.00 | Cr√©ation avanc√©e |

**Bloom's Taxonomy:**

| Level | Cognitive Load | Verbs |
|-------|----------------|-------|
| REMEMBER | < 0.15 | d√©finir, lister, identifier |
| UNDERSTAND | 0.15-0.35 | expliquer, d√©crire, interpr√©ter |
| APPLY | 0.35-0.50 | utiliser, impl√©menter, r√©soudre |
| ANALYZE | 0.50-0.70 | comparer, diff√©rencier, examiner |
| EVALUATE | 0.70-0.85 | critiquer, justifier, recommander |
| CREATE | > 0.85 | concevoir, construire, d√©velopper |

### Endpoints API MAESTRO (Port 8010)

| Endpoint | Description |
|----------|-------------|
| `GET /health` | Health check |
| `POST /api/v1/courses/generate` | D√©marrer g√©n√©ration course |
| `GET /api/v1/courses/jobs/{job_id}` | Status du job |
| `GET /api/v1/courses/{course_id}` | R√©cup√©rer le cours g√©n√©r√© |
| `POST /api/v1/domain/analyze` | Analyser un domaine (preview) |
| `POST /api/v1/concepts/extract` | Extraire concepts d'un th√®me |
| `GET /api/v1/config/progression-paths` | Paths de progression disponibles |
| `GET /api/v1/config/skill-levels` | Niveaux de comp√©tence |
| `GET /api/v1/config/bloom-levels` | Niveaux Bloom |

### Fichiers Cr√©√©s

**Nouveau microservice:**
```
services/maestro-engine/
‚îú‚îÄ‚îÄ main.py                           # FastAPI service
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ data_models.py                # Concept, Lesson, Module, CoursePackage
‚îú‚îÄ‚îÄ engines/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ domain_discovery.py           # Layer 1
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_graph.py            # Layer 2
‚îÇ   ‚îú‚îÄ‚îÄ difficulty_calibrator.py      # Layer 3
‚îÇ   ‚îî‚îÄ‚îÄ curriculum_sequencer.py       # Layer 4
‚îî‚îÄ‚îÄ generators/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ content_generator.py          # Layer 5
```

**Enrichissement course-generator (Phase A):**
```
services/course-generator/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ difficulty_models.py          # DifficultyVector, CalibratedConcept, BloomLevel
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ difficulty_calibrator.py      # DifficultyCalibratorService
‚îÇ   ‚îú‚îÄ‚îÄ curriculum_sequencer.py       # CurriculumSequencer, LearningPath
‚îÇ   ‚îú‚îÄ‚îÄ exercise_generator.py         # PracticalExercise, ExerciseGenerator
‚îÇ   ‚îú‚îÄ‚îÄ maestro_adapter.py            # Adapter pour communication HTTP
‚îÇ   ‚îú‚îÄ‚îÄ quiz_generator.py             # + BLOOM_QUESTION_MAPPING
‚îÇ   ‚îî‚îÄ‚îÄ knowledge_graph.py            # + topological_sort(), get_learning_order()
```

**Enrichissement presentation-generator:**
```
services/presentation-generator/
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ presentation_models.py        # + ScriptSegmentType, ScriptSegment, script_segments
```

### Configuration Docker

```yaml
# docker-compose.yml
maestro-engine:
  build:
    context: ./services/maestro-engine
    dockerfile: Dockerfile
  container_name: viralify-maestro-engine
  ports:
    - "8010:8008"
  environment:
    - OPENAI_API_KEY=${OPENAI_API_KEY}
    - OPENAI_MODEL=gpt-4o-mini
  networks:
    - tiktok-network
```

**Variable d'environnement course-generator:**
```env
MAESTRO_ENGINE_URL=http://maestro-engine:8008
```

### Utilisation de l'Adapter

```python
from services.maestro_adapter import get_maestro_adapter, GenerationMode

adapter = get_maestro_adapter()

# V√©rifier disponibilit√©
if await adapter.is_available():
    # G√©n√©rer un cours avec MAESTRO
    job = await adapter.generate_course(
        subject="Python Programming",
        progression_path="beginner_to_intermediate",
        num_modules=5,
        language="fr",
    )

    # Polling du status
    while job.status != "completed":
        await asyncio.sleep(5)
        job = await adapter.get_job_status(job.job_id)

    # R√©cup√©rer le cours
    course = await adapter.get_course(job.job_id)

    # Convertir au format Viralify
    viralify_course = adapter.convert_to_viralify_format(course)
```

---

## Notes importantes

- Les volumes Docker persistants sont configur√©s pour `/tmp/viralify/videos`, `/tmp/presentations`, `/app/output`, `/tmp/viralify/diagrams`
- Les timeouts OpenAI sont fix√©s √† 120s avec 2 retries
- Le frontend n√©cessite un rebuild Docker apr√®s modification des fichiers
- pgvector utilise l'index HNSW pour la recherche vectorielle rapide
- Les webhooks Stripe/PayPal doivent √™tre configur√©s dans les dashboards respectifs
- **Graphviz** est requis pour la g√©n√©ration de diagrammes avec la librairie Diagrams
- **visual-generator** est un microservice isol√© (port 8003) - les d√©pendances lourdes (Graphviz, Diagrams) y sont centralis√©es
- La complexit√© des diagrammes s'adapte automatiquement selon `target_audience` de la pr√©sentation
- **Kroki** est self-hosted pour le rendu Mermaid (privacy + reliability), avec fallback vers mermaid.ink si indisponible
- **maestro-engine** est un microservice isol√© (port 8010) pour la g√©n√©ration de cours avec calibration 4D de difficult√©
- **nexus-engine** est le service de g√©n√©ration de code p√©dagogique avec LLM multi-provider

---

## TODO - T√¢ches en attente

### S√©curit√© Nginx (Priorit√©: Moyenne)

Ajouter des r√®gles de s√©curit√© √† nginx pour bloquer les scans de bots malveillants :

1. **Bloquer les User-Agents vides ou suspects**
2. **Rate limiting sur les 404** (fail2ban ou nginx limit_req)
3. **Bloquer les chemins WordPress/PHP connus** :
   - `/wp-admin/`, `/wp-content/`, `/wp-includes/`
   - `*.php` (sauf endpoints l√©gitimes)
   - `/.env`, `/.git/`, `/config/`
4. **Optionnel** : Int√©gration Cloudflare pour filtrage DDoS

**Fichier √† modifier** : `/opt/viralify/nginx/conf.d/app.conf`

### Corrections Lecture Editor (FAIT - 2026-01-30)

- [x] Images m√©dia 404 - Corrig√© (nginx routing avec `^~` et `rewrite`)
- [x] Perte de focus formulaires - Corrig√© (EditableField m√©moris√©)
- [x] Bouton R√©g√©n√©rer - Corrig√© (endpoint `/slides/preview`)
- [x] Bouton Recomposer - Corrig√© (quality `'1080p'`)
- [x] Noms conteneurs nginx - Corrig√© (`viralify-*` prefix)

---

## Phase 9 - NEXUS Engine & Job Management (IMPL√âMENT√â)

### 9A: NEXUS Engine - G√©n√©ration de Code P√©dagogique

**Port:** 8011
**R√¥le:** G√©n√©ration de code structur√© pour les cours avec explications p√©dagogiques.

**Architecture:**
```
services/nexus-engine/
‚îú‚îÄ‚îÄ main.py                     # FastAPI service
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py             # NEXUSPipeline orchestration
‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îî‚îÄ‚îÄ llm_provider.py         # Multi-provider LLM (OpenAI, Groq, Anthropic, Ollama)
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ data_models.py          # NexusRequest, NexusResponse, CodeSegment
```

**Fonctionnalit√©s:**
- G√©n√©ration de code par segments avec explications
- Support multi-langage (Python, JavaScript, Go, Rust, etc.)
- Niveaux de comp√©tence (beginner ‚Üí expert)
- Verbosit√© configurable (minimal, standard, verbose, production)
- Inclusion des erreurs courantes √† √©viter
- Evolution progressive du code (v1 ‚Üí v2 ‚Üí v3)

**Endpoints:**
- `POST /api/v1/nexus/generate-sync` - G√©n√©ration synchrone
- `POST /api/v1/nexus/generate` - G√©n√©ration async (retourne job_id)
- `GET /api/v1/nexus/jobs/{job_id}` - Status du job
- `POST /api/v1/nexus/decompose` - D√©composition de domaine uniquement

**Multi-Provider LLM avec Retry:**
```python
# providers/llm_provider.py
- Retry automatique pour r√©ponses vides (3 tentatives)
- Backoff exponentiel (2s, 4s, 6s)
- Parsing JSON robuste avec 5 strat√©gies de r√©cup√©ration
- Support JSON mode avec fallback
```

### 9B: Job Management - Retry, Cancel, Error Queue

**Fonctionnalit√©s:**
- **Retry:** Relancer une lecture/sc√®ne √©chou√©e
- **Cancel:** Annuler un job en cours
- **Error Queue:** File d'attente des erreurs avec contenu √©ditable

**Endpoints presentation-generator:**
- `GET /api/v1/presentations/jobs/v3/{job_id}/errors` - Liste erreurs √©ditables
- `PATCH /api/v1/presentations/jobs/v3/{job_id}/lessons/{scene_index}` - Modifier contenu avant retry
- `POST /api/v1/presentations/jobs/v3/{job_id}/lessons/{scene_index}/retry` - Retry une sc√®ne
- `POST /api/v1/presentations/jobs/v3/{job_id}/retry` - Retry toutes les erreurs
- `POST /api/v1/presentations/jobs/v3/{job_id}/cancel` - Annuler le job
- `POST /api/v1/presentations/jobs/v3/{job_id}/rebuild` - Reconstruire la vid√©o finale

**Frontend:**
```
frontend/src/app/dashboard/studio/courses/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ JobErrorQueue.tsx       # Affichage erreurs √©ditables
‚îÇ   ‚îî‚îÄ‚îÄ JobControls.tsx         # Boutons retry/cancel
‚îî‚îÄ‚îÄ hooks/
    ‚îî‚îÄ‚îÄ useJobManagement.ts     # Hook pour API job management
```

### 9C: Progressive Download - Lessons Individuelles

Les vid√©os de le√ßons sont disponibles **d√®s qu'elles sont termin√©es**, sans attendre la vid√©o finale.

**Endpoint:**
- `GET /api/v1/presentations/jobs/v3/{job_id}/lessons` - Liste le√ßons disponibles

**R√©ponse:**
```json
{
  "job_id": "xxx",
  "status": "processing",
  "total_lessons": 10,
  "completed": 6,
  "lessons": [
    {
      "scene_index": 0,
      "title": "Introduction",
      "video_url": "https://...",
      "duration": 45.2,
      "status": "ready",
      "ready_at": "2026-01-29T10:30:00Z"
    }
  ],
  "final_video_url": null
}
```

### 9D: Lecture Editor - √âdition Slides/Voiceover

**Objectif:** Permettre l'√©dition du contenu d'une lecture apr√®s g√©n√©ration.

**Architecture:**
```
services/course-generator/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ lecture_editor.py       # LectureEditorService, LectureComponentsRepository
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ lecture_components.py   # SlideComponent, VoiceoverComponent, CodeBlockComponent
```

**Endpoint:**
- `GET /api/v1/courses/jobs/{job_id}/lectures/{lecture_id}/components` - R√©cup√©rer composants √©ditables

**Stockage PostgreSQL:**
```sql
CREATE TABLE lecture_components (
    id VARCHAR(255) PRIMARY KEY,
    lecture_id VARCHAR(255) NOT NULL,
    job_id VARCHAR(255) NOT NULL,
    slides_json JSONB NOT NULL DEFAULT '[]',
    voiceover_json JSONB,
    generation_params_json JSONB NOT NULL DEFAULT '{}',
    total_duration FLOAT NOT NULL DEFAULT 0.0,
    video_url TEXT,
    presentation_job_id VARCHAR(255),
    status VARCHAR(50) NOT NULL DEFAULT 'completed',
    is_edited BOOLEAN NOT NULL DEFAULT FALSE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

**Flux de r√©cup√©ration:**
1. Frontend clique "Contenu" sur une lecture
2. API v√©rifie si composants en DB
3. Si non ‚Üí r√©cup√®re depuis presentation-generator via `presentation_job_id`
4. Stocke en DB pour √©ditions futures
5. Retourne slides, voiceover_text, code_blocks √©ditables

**Corrections r√©centes (Janvier 2026):**
- `fix: preserve lecture updates when processing orchestrator result` - Les mises √† jour de lecture (status, presentation_job_id) ne sont plus √©cras√©es
- `fix: store slides in V3 job for lecture editor retrieval` - Les slides compl√®tes sont maintenant stock√©es dans le job Redis

---

## Phase 10 - Optimisations Performance (EN COURS)

### FFmpeg CPU Optimization

**Probl√®me:** FFmpeg utilisait 300%+ CPU sur serveur 4 vCPU partag√©.

**Solutions appliqu√©es:**
1. Preset `veryfast` au lieu de `medium` (moins de CPU)
2. Threads par processus: 1 ‚Üí 2 (meilleur parall√©lisme)
3. `FFMPEG_MAX_CONCURRENT=1` (limite processus simultan√©s)

**Fichier:** `services/presentation-generator/services/ffmpeg_timeline_compositor.py`

### Groq Rate Limiting

**Probl√®me:** Groq retourne parfois des r√©ponses vides (rate limiting).

**Solution:** Retry avec backoff dans `llm_provider.py`
```python
max_json_retries = 3
for attempt in range(max_json_retries):
    if not response.content:
        time.sleep(2.0 * (attempt + 1))  # 2s, 4s, 6s
        continue
```

### Migration GPT-4-Turbo ‚Üí Groq/DeepSeek

**Fichiers utilisant encore gpt-4-turbo-preview:**
| Service | Fichier |
|---------|---------|
| course-generator | `agents/base.py`, `services/course_planner.py`, `agents/production_graph.py` |
| presentation-generator | `services/diagram_generator.py`, `services/langgraph_orchestrator.py`, `services/agents/scene_planner.py`, `services/presentation_planner.py` |
| media-generator | `services/ai_video_planner.py`, `main.py` |
| content-generator | `main.py` |

**Recommandation:** Utiliser variable `LLM_PROVIDER` pour basculer vers Groq (95% moins cher)

---

## Kubernetes Deployment

Manifests disponibles dans `/k8s` pour d√©ploiement sur cloud (DigitalOcean, AWS, GCP).

```
k8s/
‚îú‚îÄ‚îÄ namespace.yaml
‚îú‚îÄ‚îÄ configmap.yaml
‚îú‚îÄ‚îÄ secrets.yaml
‚îú‚îÄ‚îÄ deployments/
‚îÇ   ‚îú‚îÄ‚îÄ frontend.yaml
‚îÇ   ‚îú‚îÄ‚îÄ api-gateway.yaml
‚îÇ   ‚îú‚îÄ‚îÄ course-generator.yaml
‚îÇ   ‚îú‚îÄ‚îÄ presentation-generator.yaml
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ *.yaml
‚îî‚îÄ‚îÄ ingress.yaml
```
